{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welcome to Mole","text":"<p>Mole is a tool to assist with testing and experimentation involving robots and autonomous systems. It can facilitate the following:</p> <ul> <li>test and experiment execution: tracking who, what, where, when, why, and how of the experiment</li> <li>data collection: acquiring targeted data based on events representing \"conditions of interest\"</li> <li>orchestration: controlling experiment infrastructure to enable dyamic yet repeatable scenarios</li> <li>monitoring: confirming system, infrastructure, and personnel status over time</li> <li>analysis and reporting: generating pre-defined performance metrics and figures to rapidly produce stakeholder reports</li> </ul> <p>Mole originated as a way to collect data for uncrewed ground vehicles and to automatically generate reports with summary metrics and figures.  It now finds a number of additional use cases spanning single and multi-vehicle operations within air, ground, and sea domains -- both live and virtual.</p> <p>This documentation seeks to provide sufficient background to enable using Mole or contributing to its development.</p>"},{"location":"basic_config.html","title":"Configuration","text":""},{"location":"basic_config.html#first-steps","title":"First Steps","text":"<p>If we're starting with a blank slate, we have a couple initial steps to go through to configure Django. We need to create a series of Django model instances to tailor the Mole instrumentation to a specific domain. There are two ways to create instances: using the Django ORM or using third-party library <code>factory_boy</code>. The main difference between the two is how much data must be specified. The ORM requires all the fields to be filled out but <code>factory_boy</code> is configured to fill in fields that are left blank. Regardless of which is chosen, this should be implemented in a custom Django command. An example of one can be found at <code>mole/data_collection/management/commands/configure_mole.py</code>.</p>"},{"location":"basic_config.html#locations","title":"Locations","text":"<p>The first thing we need to create is a location. </p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nlocation_1 = dcm.Location.objects.create(\n    name=\"Location 1\", \n    description=\"description of location 1\", \n    point=\"POINT(-117.248 32.709)\",\n    timezone=\"America/Los_Angeles\",\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nlocation_1 = factories.LocationFactory(\n    name=\"Location 1\", \n    description=\"description of location 1\", \n    point=\"POINT(-117.248 32.709)\",\n    timezone=\"America/Los_Angeles\",\n)\n</code></pre> <p>The name and description fields are self-explanatory. The point field is a well-known text representation (WKT) of a point geometry. The timezone field is a string indicating the TZ database name.</p>"},{"location":"basic_config.html#campaigns","title":"Campaigns","text":"<p>Next we need to create a campaign. A campaign can represent a high level field experiment or test event. </p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\ncampaign_1 = dcm.Campaign.objects.create(\n    name=\"Test Event 1\",\n    description=\"info about test event 1\",\n    start_datetime=\"2018-10-21T05:00:00-0800\",\n    end_datetime=\"2018-10-25T19:00:00-0800\",\n    location=location_1,\n    trial_id_major_name=\"Day\",\n    trial_id_minor_name=\"Shift\",\n    trial_id_micro_name=\"Attempt\",\n)\n</code></pre> <pre><code>from data_collection.factories import factories\ncampaign_1 = factories.CampaignFactory(\n    name=\"Test Event 1\",\n    description=\"info about test event 1\",\n    start_datetime=\"2018-10-21T05:00:00-0800\",\n    end_datetime=\"2018-10-25T19:00:00-0800\",\n    location=location_1,\n    trial_id_major_name=\"Day\",\n    trial_id_minor_name=\"Shift\",\n    trial_id_micro_name=\"Attempt\",\n)\n</code></pre> <p><code>start_datetime</code> and <code>end_datetime</code> indicate the start and end time respectively. </p> <p><code>location</code> should be a reference to the Location object created earlier. </p> <p><code>trial_id_major_name</code>, <code>trial_id_minor_name</code>,  and <code>trial_id_micro_name</code> are strings that describe the numbering scheme for trials. Each trial has a major, minor, and micro id, visualized as <code>x.y.z</code>. For example, the following code block marks the <code>x</code> id as the day. These strings are optional and will default to the empty string if not specified. </p>"},{"location":"basic_config.html#scenarios","title":"Scenarios","text":"<p>Next we'll create a Scenario. But first we need to create a Test Method. A Test Method represents a defined procedure to test a capability. It could be focused on a low level capability such as obstacle detection or path planning, or a system-level test that is intended to exercise the fully-integrated system. A Scenario is a specific instantiation of a Test Method that defines parameters that may be variable in the Test Method (e.g., location, number of agents, test duration, dynamic elements, etc.). So the Test Method might be \"Persistent Swarm Surveillance\", and the Scenario might be \" 3-agent surveillance\". This is intended to allow association of similar Test Methods while allowing some variation in location or parameters.   Django ORMFactory Boy <pre><code>import data_collection.models as dcm\ntest_method = dcm.TestMethod.objects.create(\n    name=\"Interactive Swarm Exercise\",\n    description=\"Testing swarm capabilities\",\n    version_major=1,\n    version_minor=0,\n    version_micro=0,\n    variant=\"autonomy\",\n)\n</code></pre> <pre><code>from data_collection.factories import factories\ntest_method = factories.TestMethodFactory(\n    name=\"Interactive Swarm Exercise\",\n    description=\"Testing swarm capabilities\",\n    version_major=1,\n    version_minor=0,\n    version_micro=0,\n    variant=\"autonomy\",\n)\n</code></pre> <p>The version numbers and variant can be used to track changes to test procedures. </p> <p>Now we can create the scenario.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nscenario_1 = dcm.Scenario.objects.create(\n    name=\"Scenario 1\",\n    description=\"description of scenario 1\",\n    location=location_1,\n    test_method=test_method,\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nscenario_1 = factories.ScenarioFactory(\n    name=\"Scenario 1\",\n    description=\"description of scenario 1\",\n    location=location_1,\n    test_method=test_method,\n)\n</code></pre> <p>The scenario's location could be the same or different than the campaign's location. If different, follow the steps for creating a location to create another one.</p>"},{"location":"basic_config.html#trials","title":"Trials","text":"<p>Now we move on to our trials. A Trial can represent a single run or attempt. Events of interest or data about the run can be saved in these trials, giving us an easy container to compare and contrast test results. Since trials contain a lot of data about a run, we'll need to create a couple of pre-requisite instances. The first is a Tester which needs both a user and a role.</p> <p>We use the Django authentication user so unlike the other models, we have to use the <code>factory_boy</code> implementation to ensure that the password is saved correctly.</p> Factory Boy <pre><code>from data_collection.factories import factories\nmain_user = factories.UserFactory(\n    username=\"admin\", \n    password=\"admin\",\n)\n</code></pre> <p>Warning</p> <p>You'll want to adjust this to have more secure credentials.</p> <p>Next we'll create the role.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nmy_role = dcm.Role.objects.create(\n    name=\"test_administrator\", \n    description=\"description of test administrator\",\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nmy_role = factories.RoleFactory(\n    name=\"test_administrator\", \n    description=\"description of test administrator\",\n)\n</code></pre> <p>Now that we have both a user and a role, we can create a tester.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nmy_tester = dcm.Tester.objects.create(\n    user=main_user, \n    role=my_role,\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nmy_tester = factories.TesterFactory(\n    user=main_user, \n    role=my_role,\n)\n</code></pre> <p>Next we need a system configuration. A system configuration can  consist of one or more capability under test, each of which has a performer. We'll start at the bottom with the performer.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nperformer_1 = dcm.Performer.objects.create(\n    name=\"Integrator Team 1\", \n    description=\"info about team 1\",\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nperformer_1 = factories.PerformerFactory(\n    name=\"Integrator Team 1\", \n    description=\"info about team 1\",\n)\n</code></pre> <p>Next up is capability under test.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\ncapability_under_test = dcm.CapabilityUnderTest.objects.create(\n    name=\"Swarm Capability\",\n    description=\"Swarm Capability\",\n    performer=performer_1,\n)\n</code></pre> <pre><code>from data_collection.factories import factories\ncapability_under_test = factories.CapabilityUnderTestFactory(\n    name=\"Swarm Capability\",\n    description=\"Swarm Capability\",\n    performer=performer_1,\n)\n</code></pre> <p>Then we round it out with a system configuration.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nsys_conf = dcm.SystemConfiguration.objects.create(\n    name=\"System Configuration 1\",\n    description=\"total set of performers\",\n    capabilities_under_test=(capability_under_test,),\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nsys_conf = factories.SystemConfigurationFactory(\n    name=\"System Configuration 1\",\n    description=\"total set of performers\",\n    capabilities_under_test=(capability_under_test,),\n)\n</code></pre> <p>Next we have to create a test condition, as well as a weather instance. First we'll start with the weather.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\ncurrent_weather = dcm.Weather.objects.create(\n    name=\"Sunny\",\n    description=\"no clouds in the sky\",\n)\n</code></pre> <pre><code>from data_collection.factories import factories\ncurrent_weather = factories.WeatherFactory(\n    name=\"Sunny\",\n    description=\"no clouds in the sky\",\n)\n</code></pre> <p>Then onto the test condition.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nmy_test_condition = dcm.TestCondition.objects.create(\n    weather=current_weather,\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nmy_test_condition = factories.TestConditionFactory(\n    weather=current_weather,\n)\n</code></pre> <p>Now we can finally create an initial trial.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\ndcm.Trial.objects.create(\n    id_major=0,\n    id_minor=0,\n    id_micro=0,\n    campaign=campaign_1,\n    scenario=scenario_1,\n    testers=(my_tester,),\n    test_condition=my_test_condition,\n    system_configuration=sys_conf,\n    start_datetime=\"2018-10-22T07:00:00-0800\",\n    reported=False,\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nfactories.TrialFactory(\n    id_major=0,\n    id_minor=0,\n    id_micro=0,\n    campaign=campaign_1,\n    scenario=scenario_1,\n    testers=(my_tester,),\n    test_condition=my_test_condition,\n    system_configuration=sys_conf,\n    start_datetime=\"2018-10-22T07:00:00-0800\",\n    reported=False,\n)\n</code></pre> <p>The ternary id (<code>id_major</code>, <code>id_minor</code>, <code>id_micro</code> taken together) have to be unique within each campaign, but there is no restriction otherwise on their integer values.</p> <p><code>reported</code> is a boolean flag that will tell the report generator whether or not to create graphs and charts for this trial.</p>"},{"location":"basic_config.html#event-types","title":"Event Types","text":"<p>With a trial in place, we can start creating event types to track the things we are interested in. These event types can represent 'bookmarks' during the test run or a change in state. It can be used to show an interaction of interest or a noteworthy exchange.</p> <p>We'll first create an event level.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nevent_level = dcm.EventLevel.objects.create(\n    name=\"Info\", \n    description=\"Informational events\", \n    key=\"info\", \n    visibility=1,\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nevent_level = factories.EventLevelFactory(\n    name=\"Info\", \n    description=\"Informational events\", \n    key=\"info\", \n    visibility=1,\n)\n</code></pre> <p>The name and key fields are both unique strings and the visibility is set to some integer value, used to dictate a hierarchy of event types.</p> <p>Now we move on to the event type itself.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\ndcm.EventType.objects.create(\n    name=\"Interaction\",\n    description=\"interaction of note\",\n    event_level=event_level,\n    is_manual=True,\n    has_duration=False,\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nfactories.EventTypeFactory(\n    name=\"Interaction\",\n    description=\"interaction of note\",\n    event_level=event_level,\n    is_manual=True,\n    has_duration=False,\n)\n</code></pre>"},{"location":"basic_config.html#entities","title":"Entities","text":"<p>This model provides an abstraction for any unit or system we wish to track. This could be a system that's undergoing testing or an orchestration element that we're configuring. </p> <p>Each entity will need an entity type. We can also assign a list of capabilities to an entity type, signifying that every entity of this type has these properties. We can further distinguish individual entities by assigning mods to them, where mods can have multiple capabilities.</p> <p>We'll start with defining a couple of capabilities.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nradar_cap = dcm.Capability.objects.create(\n    name=\"radar\", \n    description=\"24 GHz Radar\",\n    display_name=\"Radar\",\n)\nble_cap = dcm.Capability.objects.create(\n    name=\"ble\", \n    description=\"Capability using Bluetooth Low Energy\",\n    display_name=\"Bluetooth Low Energy\",\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nradar_cap = factories.CapabilityFactory(\n    name=\"radar\", \n    description=\"Radar Capability\",\n    display_name=\"Radar\",\n)\nble_cap = factories.CapabilityFactory(\n    name=\"ble\", \n    description=\"Capability using Bluetooth Low Energy\",\n    display_name=\"Bluetooth Low Energy\",\n)\n</code></pre> <p><code>display_name</code> is a more human-friendly string that can be used for a UI for example.</p> <p>Next we'll make a mod combining the two capabilities.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\ncomms_mod = dcm.Mod.objects.create(\n    name=\"comms_mod\", \n    description=\"A combination mod that contains both radar and bluetooth low energy\",\n    display_name=\"Combined communication mod\",\n)\ncomms_mod.capabilities.set([radar_cap, ble_cap])\n</code></pre> <pre><code>from data_collection.factories import factories\ncomms_mod = factories.ModFactory(\n    name=\"comms_mod\", \n    description=\"A combination mod that contains both radar and bluetooth low energy\",\n    display_name=\"Combined communication mod\",\n    capabilities=[radar_cap, ble_cap],\n)\n</code></pre> <p>Note that when using the Django ORM, the process to add a capability to a mod is slightly more complicated than the creation of the mod. It must be set outside of the creation of the mod due to technical limitations. This occurs in various other models throughout Mole as well. This limitation does not occur in the <code>factory_boy</code> factories.</p> <p>We'll make an entity type next, a ugv entity type with an inherent radar capability.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nugv_type = dcm.EntityType.objects.create(\n    name=\"ugv\", \n    description=\"Unmanned ground vehicle t ype\",\n    display_name=\"UGV\",\n)\nugv_type.capabilities.set([radar_cap])\n</code></pre> <pre><code>from data_collection.factories import factories\nugv_type = factories.EntityTypeFactory(\n    name=\"ugv\", \n    description=\"Unmanned ground vehicle type\",\n    display_name=\"UGV\",\n    capabilities=[radar_cap],\n)\n</code></pre> <p>Then we can make an individual entity that contains the <code>comms_mod</code> mod.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nalpha_1 = dcm.Entity.objects.create(\n    name=\"alpha_1\",\n    description=\"A motorized ground rover with multi-comms\",\n    entity_type=ugv_type,\n    display_name=\"Alpha 1\",\n    physical_id=\"raspberry pi 3b+\",\n)\nalpha_1.mods.set([comms_mod])\n</code></pre> <pre><code>from data_collection.factories import factories\nalpha_1 = factories.EntityFactory(\n    name=\"alpha_1\",\n    description=\"A motorized ground rover with multi-comms\",\n    entity_type=ugv_type,\n    display_name=\"Alpha 1\",\n    physical_id=\"raspberry pi 3b+\",\n    mods=[comms_mod],\n)\n</code></pre>"},{"location":"basic_config.html#entitygroups","title":"EntityGroups","text":"<p>We can also cluster entities together if there is some other commonality between them. They could be part of a specific scenario, which we could then relate directly on the scenario. They might share a physical property that is not otherwise recorded in Mole or used to denote valid entities for a entity state. Alternatively, EntityGroups can be used to 'tag' entities with an attribute. </p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nrpi_group = dcm.EntityGroup.objects.create(\n    name=\"rpi\",\n    description=\"Entities based on a Raspberry Pi platform\",\n    basemap_element=False,\n)\nalpha_1.groups.set([rpi_group])\n</code></pre> <pre><code>from data_collection.factories import factories\nrpi_group = factories.EntityGroupFactory(\n    name=\"rpi\",\n    description=\"Entities based on a Raspberry Pi platform\",\n    basemap_element=False,\n)\nalpha_1.groups.set([rpi_group])\n</code></pre> <p><code>basemap_element</code> indicates whether or not the entities in the given group should be drawn on the front end map or not. </p>"},{"location":"basic_config.html#regions","title":"Regions","text":"<p>Regions represent geographical areas of interest. They can represent a keep-out zone, an activation area, an entity's area of control, etc. Regions are named and are defined by their region type, the geometry of the area it represents, a z-value layer, and an optional geographical point. Scenarios can also optionally be related with specific regions. This could happen if different scenarios affect different test areas or if an activation area changes between rounds. However this relation would need to be specified on the <code>scenario</code> creation rather than the <code>region</code> creation. </p> <p>We'll create a region type first.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nkoz_type = dcm.RegionType.objects.create(\n    name=\"keep_out_zone\",\n    description=\"A keep-out zone\",\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nkoz_type = factories.RegionTypeFactory(\n    name=\"keep_out_zone\",\n    description=\"A keep-out zone\",\n)\n</code></pre> <p>Now we'll create the region.</p> Django ORMFactory Boy <pre><code>import json\nimport data_collection.models as dcm\ngeometry = {\n    \"coordinates\": [\n        [\n            [-117.2443986,32.6648668],\n            [-117.2354937,32.6667635],\n            [-117.2352576,32.6721824],\n            [-117.2471023,32.6707012],\n            [-117.2443986,32.6648668]\n        ]\n    ],\n    \"type\": \"Polygon\"\n}\ndcm.Region.objects.create(\n    name=\"keep_out_zone_command_center\",\n    region_type=koz_type,\n    geom=json.dumps(geometry),\n    z_layer=1.0,\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nfactories.RegionFactory(\n    name=\"keep_out_zone_command_center\",\n    region_type=koz_type,\n    geom=\"POLYGON ((-117.2443986 32.6648668, -117.2354937 32.6667635, -117.2354722 32.6697800, -117.2465873 32.6684434, -117.2443986 32.6648668))\",\n    z_layer=1.0,\n    key_point=None,\n)\n</code></pre> <p><code>geom</code> can take either a GeoJSON string (as seen in the Django ORM example) or WKT (as seen in the <code>factory_boy</code> example).</p> <p><code>z_layer</code> can be an arbitrary float value that makes sense in the given context.</p> <p>Note using <code>factory_boy</code> for Region</p> <p>If <code>key_point</code> is not explicitly set to <code>None</code>, the factory will create an arbitrary point for it.</p>"},{"location":"basic_config.html#posesources","title":"PoseSources","text":"<p>Mole also has the ability to track entities as they move. We do this through the <code>Pose</code> model. Poses have a <code>PoseSource</code>, which distinguishes poses of different origins. </p> <p>For creating poses later, we'll need to have at least one <code>PoseSource</code>.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\ngps_pose_source = dcm.PoseSource.objects.create(\n    name=\"GPS\",\n    description=\"GPS provided pose source\",\n)\n</code></pre> <pre><code>from data_collection.factories import factories\ngps_pose_source = factories.PoseSourceFactory(\n    name=\"GPS\",\n    description=\"GPS provided pose source\",\n)\n</code></pre>"},{"location":"basic_config.html#servers","title":"Servers","text":"<p>In order to display maps, we'll need to set up a <code>Server</code>. This is a model that captures parameters used for the map display. </p> <p>We'll start with a <code>ServerType</code>.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nserver_type = dcm.ServerType.objects.create(\n    name=\"Tiled Aerial Imagery Server\",\n    description=\"Server that provides tiled aerial imagery\",\n    key=\"tiled_imagery\",\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nserver_type = factories.ServerTypeFactory(\n    name=\"Tiled Aerial Imagery Server\",\n    description=\"Server that provides tiled aerial imagery\",\n    key=\"tiled_imagery\",\n)\n</code></pre> <p>Then we'll create some <code>ServerParams</code>.</p> Django ORMFactory Boy <pre><code>import json\nimport data_collection.models as dcm\nvalue = {\n    \"lat\":\"32.709\",\n    \"lng\":\"-117.248\",\n}\nmap_center_param = dcm.ServerParam.objects.create(\n    name=\"Map Center\",\n    description=\"provides parameters for a map's center point\",\n    param=\"mapOptions\",\n    value=json.dumps(value),\n)\nzoom_param = dcm.ServerParam.objects.create(\n    name=\"Zoom levels\",\n    description=\"provides parameters for a map's zoom levels\",\n    param=\"mapOptions\",\n    value='{\"minZoom\":1, \"maxZoom\":20}',\n)\n</code></pre> <pre><code>import json\nfrom data_collection.factories import factories\nvalue = {\n    \"lat\":\"32.709\",\n    \"lng\":\"-117.248\",\n}\nmap_center_param = factories.ServerParamFactory(\n    name=\"Map Center\",\n    description=\"provides parameters for a map's center point\",\n    param=\"mapOptions\",\n    value=json.dumps(value),\n)\nzoom_param = factories.ServerParamFactory(\n    name=\"Zoom levels\",\n    description=\"provides parameters for a map's zoom levels\",\n    param=\"mapOptions\",\n    value='{\"minZoom\":1, \"maxZoom\":20}',\n)\n</code></pre> <p>Now we can put it together into a <code>Server</code>. For using OpenStreetMap tiles, you can set the <code>base_url</code> to <code>https://a.tile.openstreetmap.org/{z}/{x}/{y}.png</code>. If using the OpenStreetMap tiles, keep the Tile Usage Policy in mind.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nserver = dcm.Server.objects.create(\n    name=\"Local World Tiles\",\n    server_type=server_type\",\n    base_url=\"http://{window.location.hostname}/maps/styles/ne_simple_style/{z}/{x}/{y}.png\",\n)\nserver.server_params.set([map_center_param, zoom_param])\n</code></pre> <pre><code>from data_collection.factories import factories\nserver = factories.ServerFactory(\n    name=\"Local World Tiles\",\n    server_type=server_type\",\n    base_url=\"http://{window.location.hostname}/maps/styles/ne_simple_style/{z}/{x}/{y}.png\",\n    server_params=[map_center_param, zoom_param],\n)\n</code></pre> <p><code>base_url</code> contains the url for the map tiles, whether that's locally served (as in our example) or remotely hosted.</p>"},{"location":"basic_config.html#further-configuration","title":"Further Configuration","text":""},{"location":"basic_config.html#game-clock","title":"Game Clock","text":"<p>See Game Clock.</p>"},{"location":"basic_config.html#scripted-events","title":"Scripted Events","text":"<p>See Scenario Scripts.</p>"},{"location":"basic_config.html#point-styles","title":"Point Styles","text":"<p>See Map/Timeline Marker Styles</p>"},{"location":"basic_config.html#entity-states","title":"Entity States","text":"<p>See Entity States</p>"},{"location":"basic_config.html#metadata-keysvalues","title":"Metadata Keys/Values","text":"<p>See Metadata Keys/Values</p>"},{"location":"basic_config.html#access-logs","title":"Access Logs","text":"<p>An access log for django can be found at <code>mole/_logs/access.log</code>. This will contain the remote address, username, date of request, where the request is for, HTTP status, response length, and referer.</p>"},{"location":"developer_angular.html","title":"User Interface","text":""},{"location":"developer_angular.html#introduction","title":"Introduction","text":"<p>The Mole user interface is built using the Angular web framework. You can read more about the Angular framework here.</p>"},{"location":"developer_angular.html#getting-started","title":"Getting Started","text":""},{"location":"developer_angular.html#install-angular-cli","title":"Install Angular CLI","text":"<p>Before beginning development, it's recommended that you insall the Angular CLI. The CLI  will give you a library of commands to generate components, services, modules, etc. as  well as check for updates and run unit tests.</p> <p>Install: <code>npm install -g @angular/cli</code></p>"},{"location":"developer_angular.html#code-styling","title":"Code Styling","text":"<ul> <li>Variables: camelCase<ul> <li>Service instances prefixed with underscore</li> </ul> </li> <li>Indentation: 2 spaces</li> <li>Curly Brackets: Openning bracket inline with header</li> </ul>"},{"location":"developer_angular.html#project-structure","title":"Project Structure","text":"<p>The root of the project's working files is <code>angular &gt; app &gt; src &gt; app</code>. The folder  structure for the project was heavily informed by this article.</p>"},{"location":"developer_angular.html#modules","title":"Modules","text":"<p>Modules can be thought of as the pages within Mole. They are composed of a module  typescript file and a component (generated seperately, see Components.  Modules define the placement and layout of the components that make up a page. When  generating a module, the Angular CLI will create a single typescript file where you can  import the resources you would like to expose to components within the module.</p> <p>Generate a module within cwd:</p> <p>Local: <code>ng g m {module_name}</code></p> <p>Shared: <code>ng g m --module shared {module_name}</code></p>"},{"location":"developer_angular.html#components","title":"Components","text":"<p>The user interface is broken into UI building blocks called \"components\". Every  component has its own html, typescript, sass, and unit test file within a containing  directory. When generating a component, the Angular CLI will create a named directory  with template component files. Every component provides a custom html tag to be used  throughout the app.</p> <p>Generate a component within cwd:</p> <p>Local: <code>ng g c {component_name}</code></p> <p>Shared: <code>ng g c --module shared {component_name}</code></p> <p>Important</p> <p>The component typescript file should be restricted to only contain view logic.  Logic outside of this scope, especially if it will be used by other components,  should be contained within a service.</p>"},{"location":"developer_angular.html#services","title":"Services","text":"<p>Services perform tasks for components and are especially useful when components are  sharing the same resources. When generating a service, the Angular CLI will create a  typescript file and unit test file within a named directory.</p> <p>Generate a local service within cwd:</p> <p>Local: <code>ng g s {service_name}</code></p> <p>Shared: <code>ng g s --module shared {service_name}</code></p>"},{"location":"developer_angular.html#models","title":"Models","text":"<p>Models are simply interfaces. All models are stored within <code>angular &gt; app &gt; src &gt; app &gt;  shared &gt; models</code>. You may allow multiple related models to share the same model  file. If your model is an interface for an api model, you will need to write an adapter  for the model. An adapter is essentially a function that taks a json object as a  paramter and returns an instance of the model (see exmple below).</p> <p>Generate a model:</p> <ol> <li>Create a new typescript file following this naming scheme: {model_name}.model.ts</li> <li>Update index.ts to export the models you created</li> </ol> <pre><code>    eventTypeAdapter(json: any): EventType {\nlet eventType: EventType = {\nurl: \"\",\nid: -1,\nname: json.name,\ndescription: json.description,\neventLevel: json.event_level,\n...\n};\n\nif (json.url) {\neventType.url = json.url.replace(\"http://django:8000\", \"\");\n}\n\nif (json.id) {\neventType.id = json.id;\n}\n\nreturn eventType;\n}\n</code></pre>"},{"location":"developer_angular.html#shared-directory","title":"Shared Directory","text":"<p>Most components can be shared among multiple modules, that's the purpose of the  <code>angular &gt; app &gt; src &gt; app &gt; shared</code> directory: to expose common components to all the  modules. If you find yourself developing a component or service that will only be used  by a single module, this code may be placed within that module's directory. </p>"},{"location":"developer_angular.html#routing","title":"Routing","text":"<p>All app routes are defined in <code>app-routing.module.ts</code>. This file contains two exported  constants: <code>routes</code> and <code>moleLinks</code>. </p> <ul> <li><code>routes</code> contains all the route objects for internal modules and are lazy loaded</li> <li><code>moleLinks</code> contains all the route objects for external links</li> </ul> <p>When you add a route object to this file, the side navigation menu is configured to  list it without any additional configuration.</p>"},{"location":"developer_angular.html#sharing-data-between-components","title":"Sharing Data Between Components","text":"<p>There are a few ways of sharing data between components, and Mole utilizes all of them.  When developing the UI, it's important to be familiar with the @Input, @Output, and  @ViewChild decorators, as well as rxjs Observables. A good resource for these concepts  can bew viewed here.</p>"},{"location":"developer_angular.html#shared-modules","title":"Shared Modules","text":"<p>The shared directly also includes two shared modules: <code>molemat.module.ts</code> and  <code>shared.module.ts</code>.</p> <ul> <li><code>molemat.module.ts</code>: This module imports and exports all Angular Material modules so they can be used  throughout the application.</li> <li><code>shared.module.ts</code>: This module imports all modules that are not Angular Material modules and exports all  shared components.</li> </ul>"},{"location":"developer_angular.html#ui-styling","title":"UI Styling","text":""},{"location":"developer_angular.html#colors","title":"Colors","text":"<p>All UI colors are defined in an Angular Material theme located in <code>angular &gt; src &gt;  styles &gt; _theme.scss</code>. Read more about theming Angular Material here.</p> <p>Important</p> <p>It is recommended not to hard-code colors within components and to reference the  theme instead.</p>"},{"location":"developer_angular.html#iconography","title":"Iconography","text":"<p>There are two different icon libraries available for use throughout the project:</p> <ul> <li>Material Design Icons<ul> <li>See usage docs here.</li> <li>See available icons here.</li> </ul> </li> <li>Font Awesome<ul> <li>See usage docs here.</li> <li>See available icons here.</li> </ul> </li> </ul>"},{"location":"developer_angular.html#point-styles","title":"Point Styles","text":"<p>Point styles define the colors and icons of map markers and event types. Read more  about point styles here.</p>"},{"location":"developer_angular.html#unit-testing","title":"Unit Testing","text":"<p>Refer to Angular Testing for more details on unit  testing.</p> <p>Run unit tests:</p> <p>From <code>angular &gt; app &gt; src &gt; app</code>, run <code>ng test</code></p>"},{"location":"developer_angular.html#development-server","title":"Development Server","text":"<p>The Angular development server hosts Mole on port <code>4200</code>. The Angular development  server automatically spins up when you start mole. As changes are made in the codebase,  the application auto-reloads to reflect the changes. This allows for a more rapid  development experience.</p>"},{"location":"developer_angular.html#serve-static-files-from-django","title":"Serve Static Files from Django","text":"<p>The Angular container is able to build the Angular files to be served statically from  Django. To build the files, use the <code>-a</code> flag on the <code>init</code> script. Mole will spin up a  one-time angular container to build the static files into the docker volume. Once  complete, the angular container will delete itself. Static files are hosted on port  <code>8000/a</code>.</p> <p>Build Angular files to be served from Django:</p> <p><code>./ml init -a</code></p>"},{"location":"developer_angular_testing.html","title":"ANGULAR MOLE TESTING","text":"<p>For Angular Mole we are using the Jasmine Unit Testing Framework.</p> <p>Another Jasmine Intro</p>"},{"location":"developer_angular_testing.html#running-tests","title":"Running Tests","text":"<p>Navigate to the app directory <code>angular/app/src/app</code> </p> <p>Then from terminal use command <code>ng test</code> to run the entire test suite. </p>"},{"location":"developer_angular_testing.html#basics-of-tests","title":"Basics Of Tests","text":"<p>Each component, pipe, service, etc has a test suite that is associated with it. To define a test suite in Jasmine we use the <code>describe</code> function that takes two parameters: - <code>String</code>: The title of the suite  - <code>function</code>: Function that implements the suite</p> <p>Each suite is made up of unit tests that are each defined with the <code>it</code> function which also takes two parameters: - <code>String</code>: Name of the unit test - <code>function</code>: Function that implements the unit test </p>"},{"location":"developer_angular_testing.html#running-in-isolation","title":"Running In Isolation","text":""},{"location":"developer_angular_testing.html#before-each-function","title":"Before Each Function","text":"<p>To Run tests in true isolation we set up all construction of (components / objects / services / etc) along with any other setup before we run an <code>it()</code> spec unit test. When <code>beforeEach()</code> is placed within the test suite <code>define()</code> it will automatically be run before each <code>it()</code> within the test suite.</p> <p><code>beforeEach()</code> contains built in <code>async</code> capabilities which automatically calls <code>done()</code> before moving on to each unit test.</p>"},{"location":"developer_angular_testing.html#after-each-function","title":"After Each Function","text":"<p>Similar to the <code>beforeEach()</code>, <code>afterEach()</code> when placed within the test suite <code>define()</code>, will run after each <code>it()</code> unit test. This is especially useful for any kind of cleanup needed or when using mock HttpCalls.</p>"},{"location":"developer_angular_testing.html#testbed","title":"TestBed","text":"<p><code>TestBed</code> is the primary API for unit testing Angular applications. <code>TestBed</code> will configure and initialize the environment which grants methods to help in construction of components, services, etc. Allows overriding  default providers, directives, pipes, modules of the test injector, which are defined in test_injector.js </p>"},{"location":"developer_angular_testing.html#configuretestingmodule","title":"configureTestingModule","text":"<p>When configuring the test environment with imports, providers, and declarations (just like one would use for component creation), the <code>configureTestingModule()</code> is used where a moduleDefinition object is passed to it. </p> <p>**For anything being tested that has dependencies on other services or whatnot, will be mocked to maintain isolation testing. To do this one overrides the component and uses factorys to generate mock objects wherever specified dependency is needed. Ex. ImageDialogComponent relies on MatDialogRef and MAT_DIALOG_DATA to build</p> <pre><code>beforeEach(async(() =&gt; {\n    TestBed.configureTestingModule({\n      declarations: [ ImageDialogComponent ]\n\n    }).overrideComponent(ImageDialogComponent, {\n      set: {\n        providers: [\n          {provide: MatDialogRef, useFactory: () =&gt; new MockMatDialogRef()},\n          {provide: MAT_DIALOG_DATA, useFactory: () =&gt; {} }\n        ],\n\n      }\n    }).compileComponents();\n  }));\n</code></pre> <p>More On Injecting Mock classes for Testing</p>"},{"location":"developer_angular_testing.html#testing-template-html-code","title":"Testing Template HTML CODE","text":"<p>When testing templates you will use the debugElement to access the DOM properties and attributes of the component</p> <pre><code>fixture = TestBed.createComponent(ImageDialogComponent);\ncomponent = fixture.debugElement.componentInstance;\n</code></pre> <p>with the debugElement one can query through css to grab any element in the DOM and test various aspects of it such as</p> <p>is it null due to a ngIf directive:</p> <pre><code>let title_heading = fixture.debugElement.query(By.css('h1'));\nexpect(title_heading).not.toBeNull();\n</code></pre> <p>does it have certain property values set:</p> <pre><code>expect(title_heading.properties.innerText.trim()).toEqual(\"Images\");\n</code></pre> <p>triggers an event tied to it (like a button with click event): </p> <pre><code>let button = fixture.debugElement.query(By.css('button'));\nbutton.triggerEventHandler('click', {});\nexpect(on_event_type_click_spy).toHaveBeenCalled();\n</code></pre> <p>(  In this example we use triggerEventHandler which takes two arguments</p> <p>1: the name of event as string, in this case 'click' </p> <p>2: the event object that will be passed  )</p> <p>** We can also test to see if the triggered event is called with a specific value with </p> <pre><code>toHaveBeenCalledWith( args )\n</code></pre> <p>***!!! WHEN TESTING TEMPLATE CODE NO CHANGES WILL HAPPEN IN TEST SUITE TILL CHANGES ARE DETECTED !!! To do this use:</p> <pre><code>detectChanges()\n</code></pre> <p>So if above button trigger event test were run without detectChanges it will fail since detectChanges was not run after initiating the triggerEventHandler so full working example would be:</p> <pre><code>let button = fixture.debugElement.query(By.css('button'));\nbutton.triggerEventHandler('click', {});\nfixture.detectChanges();\nexpect(on_event_type_click_spy).toHaveBeenCalled();\n</code></pre> <p>This applies for all changes to template such as an ngIf or ngFor based on specific conditions that were changed since test suite compiled the component to be tested.</p>"},{"location":"developer_angular_testing.html#spies","title":"Spies","text":"<p>Spies are a useful testing tool that allows one to take an object and override that objects specific method so that at anytime during the running of the test when a specific method that is being spied on is called, the specified spy function  will run instead. </p> <p>This is especially useful when you have a method that needs to call other class methods to complete. Since we want as much isolation as possible when testing we spy on these methods and return mock values to see if the outer function being tested  works.</p> <p>Ex.</p> <pre><code>//Spy on open method belonging to the components dialog object and whenever called return 7\nlet dialog_spy = spyOn(component.dialog, 'open').and.returnValue( 7 );\n</code></pre> <p>Spies will exist within the scope they are declared. Any global spies will exists throughout all of the tests while those declared within a unit test will only be available to that specific test.</p> <p>Another purpose of spies is to see if the spied on method is called or not</p> <pre><code>expect(dialog_spy).toHaveBeenCalled();\n</code></pre> <p>or if its called with specific arguments</p> <pre><code>expect(dialog_spy).toHaveBeenCalledWith( {'one': 1, 'two': 2} );\n</code></pre> <p>If a global spy is set and you need to call the actual implementation of the method use callThrough</p> <pre><code>//This will now call the original method whenever the method being spied on is called\ndialog_spy.and.callThrough();\n</code></pre> <p>!!!! You CANNOT re-declare a spy on a method if the method is already being spied upon, if this is needed  just change its value !!!!   </p> <pre><code>//change spies value from returning 7 to calling a fake function that returns the string 'hello'\nlet dialog_spy = spyOn(component.dialog, 'open').and.returnValue( 7 );\ndialog_spy.and.callFake( () =&gt; { return 'hello' } );\n</code></pre> <p>!!!!!!!!Allowing re-declaration of spies for methods can be bypassed by setting the global settings to allow it but this is    not recommended !!!!!!!!</p> <pre><code>jasmine.getEnv().allowRespy(true);\n</code></pre>"},{"location":"developer_angular_testing.html#lifecycle-hook-testing","title":"Lifecycle Hook Testing","text":"<p>When testing lifecycle hook functions that are part of the component creation process such as ngAfterInit we can mock the component to properly test these methods in isolation.  We mock the component by creating a mock class that extends the component to be tested and use spies in the method calls before calling the super.method_name()</p>"},{"location":"developer_angular_testing.html#ngonchanges","title":"ngOnChanges","text":"<p>When testing ngOnChange methods in a testbed you have to update the @input attributes through a wrapper test component and pass the changes to the component being tested... cant just set the input value and call detect, wont work....has to be updated through the view (basically angular has to do it)</p> <p>For an Example see: </p> <p><code>event-type-cards.component.spec.ts</code></p>"},{"location":"developer_angular_testing.html#consturctor-tests","title":"Consturctor Tests","text":"<p>If you need to spy on methods or have certain things set before constructor for whatever is being tested is run, a great spot to do setup is in another <code>beforeEach()</code> block. You can have multiple <code>beforeEach()</code> blocks that will all run before the creation of whatever is being tested.</p> <pre><code>//In this case say we have asyncronous setup then once done set values before creation happens during the first test\n\nbeforeEach(async(() =&gt; {\n    ....Do stuff\n  }));\n\n beforeEach(() =&gt; {\n   ...Other stuff done, now Do More Stuff\n });\n\nit('first test', ()=&gt;{\n    ...\n});\n</code></pre>"},{"location":"developer_debugger.html","title":"Debugger","text":"<p>Debugging the Mole API backend can be simplified using an IDE debugger. Mole is distributed with a configuration for debugging under Visual Studio Code. This functionality makes use of the debugpy debugger for remote debugging within a Docker container: https://code.visualstudio.com/docs/containers/debug-python. Visual Studio Code uses the <code>.vscode/launch.json</code> file to configure the remote debugging session. This file is included in the Mole repository, so no added steps should be necessary to use it.</p> <p>In order to run the debugger, the Gunicorn WSGI server must be started with a single process and the <code>debugpy</code> server must be started within it. These are accomplished by passing the <code>-d</code> parameter to either <code>./ml init</code> or <code>./ml run</code> (e.g., <code>./ml run -d</code>)</p> <p>Note</p> <p>In debug mode, Django will not serve pages until a debugger client has connected.</p> <p>When run with <code>-d</code>, once all containers have started, the Django server waits for a debugger client to \"attach\". In order to attach the Visual Studio Code debugger, click on Run -&gt; Start Debugging and select \"Django: Remote Attach\" or click on the Run/Debug icon in the side panel and click the green play icon (<code>Start Debugging</code>) with \"Django: Remote Attach\" selected from the pull-down.</p> <p> Attach to the debugger using the green play icon with \"Django: Remote Attach\" selected from the pull down.</p> <p>When the debugger client has successfully attached to the debugger server within the container, the bar at the bottom of the Visual Studio Code window may turn from blue to orange (depending on the theme in use). Additionally, the Mole terminal output indicates <code>Debugger client attached. Continuing.</code> when the debugger is successfully attached.</p> <p> Visual Studio Code debugger not attached</p> <p> Visual Studio Code debugger attached</p> <p>From here all Visual Studio Code Debugger functionality is available including the following:</p> <ul> <li>breakpoints</li> <li>logpoints</li> <li>step through / into / over</li> <li>data inspection</li> <li>watch expressions</li> <li>debug console</li> </ul> <p>For an introduction to setting breakpoints and working with the Visual Studio Code debugger, see https://code.visualstudio.com/docs/python/python-tutorial#_configure-and-run-the-debugger. More in depth documentation on working with the Visual Studio Code debugger can be found here: https://code.visualstudio.com/docs/editor/debugging</p>"},{"location":"developer_migrations.html","title":"Migrations","text":"<p>There are two primary purposes for migrations in Mole:</p> <ol> <li>To track changes made to models.py</li> <li>To bring legacy databases into compliance</li> </ol>"},{"location":"developer_migrations.html#track-model-changes","title":"Track Model Changes","text":"<p>As Mole evolves, our database model will be modified and adapted to better serve the  purposes of Mole. Django uses migration files to migrate databases into new schemas. </p> <p>Whenever a model is changed and committed, it's important to also commit the  correlating migration file. To generate the migration file, run <code>./ml django -mm</code>  while Mole is running. The new migration file will be found in the  <code>mole &gt; data_collection &gt; migrations</code> directory.</p>"},{"location":"developer_migrations.html#migrate-legacy-databases","title":"Migrate Legacy Databases","text":"<p>You may find yourself in a position where you would like to view data in mole from an  old experiment that used a different database schema. In this case you will need to  write a custom migration file and run it against your database. </p> <p>Note</p> <p>Some custom migrations have already been developed.  If you have an existing custom migration file, you can skip to step 3.</p> <ol> <li> <p>Identify the schema differences. If you have the models.py file from the time the      database was created, you can look at the models.py diff. If not, you will      need to view the database in an application like TablePlus      and take note of schema differences there.</p> </li> <li> <p>Write custom migrations. From the differences identified in the schema, follow      the Django migrations documentation      to write the migration instructions.</p> </li> <li> <p>Apply the migration. Verify the custom migration is in the      <code>mole &gt; data_collection &gt; migrations</code> directory and then shell into the Django      container. From the Django container, run      <code>./manage.py migrate data_collection [your_custom_migration]</code></p> </li> <li> <p>Verify all required migrations were made. As a quick check to see if you caught      all schema differences in your migration, run <code>./ml django -mm</code> from the. If all      differences were caught, Django will return \"No changes detected\". If not, Django      will make a new migration file with the updates that you need to make to your custom      migration file. </p> </li> <li> <p>Save a copy of your migrated database. Run <code>./ml db -b</code> to create a backup of the      database in the <code>db_backups &gt; backups</code> directory. The original DB, custom migration,      and migrated DB should be saved together.</p> </li> </ol>"},{"location":"developer_schema.html","title":"Developer schema","text":"<p>Mole supports the automatic generation of OpenAPI schemas. This will allow users to see what resources are avaliable via the Mole API.</p>"},{"location":"developer_schema.html#generating-an-openapi-schema","title":"Generating an OpenAPI Schema","text":"<p>There are two ways to generate a schema for Mole:</p> <ol> <li>Generate the schema using <code>./ml docs --generate-schema</code></li> <li>Use the docker compose exec command.</li> </ol> <pre><code>$ docker compose exec django python manage.py generateschema --file openapi_schema.yml\n</code></pre> <p>The generated schema will be located in <code>/mole/openapi_schema.yml</code>.</p>"},{"location":"developer_schema.html#rendering-the-openapi-schema-to-pdf","title":"Rendering the OpenAPI Schema to PDF","text":"<p>The openapi_schema.yml file can be rendered to a human readable .pdf file using RapiPDF</p> <ol> <li>Clone the above repository</li> <li>Copy the mole/openapi_schema.yml file to the docs/specs/ directory within the RapiPDF repository</li> <li>Instal npm if necessary</li> <li>Install yarn if necessary</li> <li>Run <code>yarn serve --port 8011</code> within the cloned RapiPDF repository</li> <li>Browse to http://localhost:8011</li> <li>Enter <code>./specs/openapi_schema.yml</code> into one of the form fields next to \"GENERATE PDF\"</li> <li>Click \"GENERATE PDF\"</li> </ol>"},{"location":"entity_states.html","title":"Entity States","text":"<p>Entity states add the ability to track how events affect entities, as well as modify  entity appearance in the UI via point style overrides and transforms. The fields in the  Entity State model describe entity point style overrides and transforms that will be  serialized when an Entity is related to an Event (seen on the <code>related_entities</code>  property on the event).</p>"},{"location":"entity_states.html#entitystate","title":"EntityState","text":"<pre><code>example_entity_state = factories.EntityStateFactory(\n    name=\"example_state\",\n    point_style_icon_transform=\"{icon}_example\",\n    point_style_color_transform=\"#00AA00\",\n    point_style_use_marker_pin_override=True,\n    point_style_marker_color_transform=\"{marker_color}33\",\n    point_style_scale_factor_override=7,\n    point_style_animation_transform=\"Previous animation: {animation}\",\n    point_style_render_as_symbol_override=True,\n)\n</code></pre> <p>Field Descriptions:</p> <ul> <li><code>name</code>: the name of the entity state</li> <li><code>point_style_icon_transform</code>: transforms or overrides the entity's icon,  transforms must use keyword <code>icon</code> in curly braces. The above example would transform  the icon string \"test.svg\" into \"test_example.svg\". Notice that transforms are applied  before the file extension.</li> <li><code>point_style_color_transform</code>: transforms or overrides the entity's color,  transforms must use keyword <code>color</code> in curly braces. Colors are represented as hex  strings. If you are confident that the entity type point style color property does not  include an alpha value, you could use the transform to add an alpha value. Otherwise,  common use for this property would be to override the color entirely. The above example  would transform the color string \"#00FF00\" into \"#00AA00\".</li> <li><code>point_style_use_marker_pin_override</code>: overrides the entity's <code>use_marker_pin</code>  property. The above example would change the property \"False\" to \"True\".</li> <li><code>point_style_marker_color_transform</code>: transforms or overrides the entity's marker  color, transforms must use keyword <code>marker_color</code> in curly braces. Colors are  represented as hex strings. If you are confident that the entity type point style  marker color property does not include an alpha value, you could use the transform to  add an alpha value. Otherwise, common use for this property would be to override the  marker color entirely. The above example would transform the color string \"#00FF00\"  into \"#00FF0033\".</li> <li><code>point_style_scale_factor_override</code>: overrides the entity's <code>scale_factor</code>  property. The above example would override the scale factor \"3\" into \"7\".</li> <li><code>point_style_animation_transform</code>: transforms or overrides the entity's animation  color, transforms must use keyword <code>animation</code> in curly braces. The above example would  change the animation \"test\" into \"Previous animation: test\".</li> <li><code>point_style_render_as_symbol_override</code>: overrides the entity's <code>render_as_symbol</code>  property. The above example would change the property \"False\" to \"True\".</li> </ul> <p>By default, the base point style will be inherited from the point style on the entity's  type. Learn more about point styles here. The fields  with the <code>_transform</code> suffix use a Python string format to inject the previous value  (from the entity's point style) into the new value using the point style property name  as the format argument. The fields with the <code>_override</code> suffix will do a direct value  override. Overrides are also possible on <code>_transform</code> fields by omitting the point  style property reference.</p> <p>The state is then associated to the <code>EntityEventRole</code> that correlates to it. </p>"},{"location":"entity_states.html#entityeventrole","title":"EntityEventRole","text":"<pre><code>example_role = factories.EntityEventRoleFactory(\n    name=\"example_role\", \n    metadata_key=example_metadatakey,\n    entity_state=example_entity_state,\n    valid_event_types=[example_event_type],\n    valid_entity_types=[example_entity_type]\n    valid_entity_groups=[example_entity_group]\n)\n</code></pre> <p>Field Descriptions:</p> <ul> <li><code>name</code>: the name of the entity event role</li> <li><code>metadata_key</code>: event metadata key used to relate an entity to the event</li> <li><code>entity_state</code>: the entity state to apply to the entity related to the event</li> <li><code>valid_event_types</code>: entities will only be related to events of an event type  listed in this field, or to an event of any type if none specified</li> <li><code>valid_entity_types</code>: entities will only be related to events if the entity's  entity type is listed in this field, or will be related regardless of entity type if  none specified</li> <li><code>valid_entity_groups</code>: entities will only be related to events if the entity is in  an entity group listed in this field, or will be related regardless of entity group if  none specified</li> </ul> <p>In brief, entity event roles define the part an entity plays in an event. </p> <p>When an event is created, the serializer will check the event <code>metadata</code> for the  <code>metadata_key</code> instance defined in the EntityEventRole instance and validate its value. If the  value of this key matches the <code>name</code> of an existing entity, the serializer will attempt  to relate the entity to the event and apply the state to the entity. </p> <p>You may optionally define entity types, event types, and <code>entity_groups</code> to qualify the  entity for state transitions in the <code>valid_entity_types</code>, <code>valid_event_types</code>, and  <code>valid_entity_groups</code> fields respectively. If either list is empty, a validation check  will not be run on it. </p> <p>Validated entities will be serialized in the <code>related_entities</code> property on the event  along with their transformed point style. The names of entities that were found in the  metadata but did not pass validation will be listed in the <code>invalid_entities</code> property  on the event. If the entity does not exist, it will be listed in the <code>unfound_entities</code>  property on the event.</p>"},{"location":"game_clock.html","title":"Game Clock","text":""},{"location":"game_clock.html#introduction","title":"Introduction","text":"<p>Often times within an experiment, it is beneficial to have a \"game clock\" view for  experiment awareness. The Game Clock is essentially a message with a clock that can  count up or down from significant events or times within a scenario.</p> <p>The Game Clock is highly configurable, allowing the user to define clock sequences as  well as responsive timers.</p>"},{"location":"game_clock.html#getting-started","title":"Getting Started","text":"<p>There are 3 steps to configuring the Game Clock:</p> <ol> <li>Define the clock phases</li> <li>Group phases into a clock configuration</li> <li>Assign clock configuration to a trial</li> </ol>"},{"location":"game_clock.html#define-the-clock-phase","title":"Define the Clock Phase","text":"<p>The clock phase model has a number of fields that allow the game clock to be extremely  configurable. Below is a table describing the options.</p> Field Description message string: The displayed message for the clock phase message_only boolean: Set true to hide the clock string countdown boolean: true if clock counting down, false if counting up duration_seconds (optional) integer: duration of clock phase in seconds starts_with_datetime (optional) datetime: clock start time starts_with_trial_start (optional) boolean: true if clock starts with trial start_datetime starts_with_trial_end (optional) boolean: true if clock ends with trial end_datetime starts_with_event_type (optional) EventType: type of event to trigger clock phase start ends_with_datetime (optional) datetime: clock end time ends_with_trial_start (optional) boolean: true if clock ends with trial start_datetime ends_with_trial_end (optional) boolean: true if clock ends with trial end_datetime ends_with_event_type (optional) EventType: type of event to trigger clock phase end <p>Currently clock phases can be pre-configured in the Mole configuration script, or they  can be posted to the API.</p>"},{"location":"game_clock.html#group-phases-in-clock-configuration","title":"Group Phases in Clock Configuration","text":"<p>The clock config model simply defines a timezone and a list of phases. The order of the  phases in the list does not matter, Mole will infer the most appropriate phase given  the state of the experiment and defined clock phases.</p>"},{"location":"game_clock.html#assign-clock-configuration-to-trial","title":"Assign Clock Configuration to Trial","text":"<p>The trial model has a clock config foreign relation, simply set this field with a  reference to the clock config.</p>"},{"location":"game_clock.html#example-game-clock-configuration","title":"Example Game Clock Configuration","text":"<pre><code># define the clock phases\ntrial_phase_1 = factories.ClockPhaseFactory(\n    message=\"Standing By\",\n    message_only=True,\n    ends_with_trial_start=True\n)\ntrial_phase_2 = factories.ClockPhaseFactory(\n    message=\"Time Until Setup\",\n    countdown=True,\n    ends_with_trial_start=True,\n    duration_seconds=900\n)\ntrial_phase_3 = factories.ClockPhaseFactory(\n    message=\"Pre-Run Checkout\",\n    countdown=True,\n    starts_with_trial_start=True,\n    duration_seconds=900\n)\ntrial_phase_4 = factories.ClockPhaseFactory(\n    message=\"Team Setup\",\n    message_only=True,\n    starts_with_trial_end=True\n)\ntrial_phase_5 = factories.ClockPhaseFactory(\n    message=\"5 minute countdown from maintenance stop event:\",\n    countdown=True,\n    duration_seconds=300,\n    starts_with_event_type=maintenance_stop_event_type\n)\n\n# define the clock configuration\ntrial_clock = factories.ClockConfigFactory(\n    name=\"Trial Clock\",\n    timezone=\"America/Los_Angeles\"\n)\n\n# add phases to clock configuration\ntrial_clock.phases.add(trial_phase_1, trial_phase_2, trial_phase_3, trial_phase_4, trial_phase_5)\n</code></pre>"},{"location":"game_clock.html#multiple-clock-instances","title":"Multiple Clock Instances","text":"<p>The Game Clock allows multiple clock instances to run at the same time. By default, the  primary clock will reference the clock configuration assigned to the current trial.  There are a few different clocks that can run parallel to the current trial clock:</p>"},{"location":"game_clock.html#reported-clock","title":"Reported Clock","text":"<p>The Reported Clock is the clock that always tracks the first \"Reported\" trial that has  the same major and minor IDs as the current trial.</p>"},{"location":"game_clock.html#minor-clock","title":"Minor Clock","text":"<p>The Minor Clock is the clock assigned to the \"Minor Trial\" that is related to the  current trial. The Minor Trial has the same major and minor IDs as the current trial,  but a zero for the micro ID.</p> <p>Example: if the current trial's ID is 2.2.1, the Minor Trial's ID is 2.2.0.</p>"},{"location":"game_clock.html#major-clock","title":"Major Clock","text":"<p>The Major Clock is the clock assigned to the \"Major Trial\" that is related to the  current trial. The Major Trial has the same major ID as the current trial,  but zeros for the minor and micro IDs.</p> <p>Example: if the current trial's ID is 2.2.1, the Minor Trial's ID is 2.0.0.</p>"},{"location":"game_clock.html#angular-distinctions","title":"Angular Distinctions","text":"<p>In Angular, these different clocks are distinguished by the mole-timer-card input:</p> <pre><code>&lt;!-- Current trial clock --&gt;\n&lt;mole-timer-card&gt;&lt;/mole-timer-card&gt;\n\n&lt;!-- Reported trial clock --&gt;\n&lt;mole-timer-card [reported]=\"true\"&gt;&lt;/mole-timer-card&gt;\n\n&lt;!-- Minor trial clock --&gt;\n&lt;mole-timer-card [minor]=\"true\"&gt;&lt;/mole-timer-card&gt;\n\n&lt;!-- Major trial clock --&gt;\n&lt;mole-timer-card [major]=\"true\"&gt;&lt;/mole-timer-card&gt;\n</code></pre>"},{"location":"getting_started.html","title":"Getting Started","text":""},{"location":"getting_started.html#requirements","title":"Requirements","text":"<p>1) Docker</p> <p>Add docker apt repository, install Docker, create <code>docker</code> group and add the user to it, then start the service. See https://docs.docker.com/engine/install/ubuntu/</p> <pre><code>$ sudo apt-get update\n$ sudo sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release\n$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n$ echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\n$ sudo apt-get update\n$ sudo apt-get install docker-ce docker-ce-cli containerd.io\n\n$ sudo groupadd docker\n$ sudo usermod -aG docker $USER\n$ sudo service docker start\n</code></pre> <p>Reboot, then confirm docker is running.</p> <pre><code>$ docker run hello-world\n</code></pre> <p>Note</p> <p>If building the Docker containers hangs in the Mole initialization step below, see Configuring Docker to Use a Different DNS Server.  This may be due to Docker's default DNS server (Google's 8.8.8.8) being blocked on your network.</p> <p>2) Docker Compose</p> <p>Install Docker Compose plugin. See https://docs.docker.com/compose/install/linux/#install-using-the-repository</p> <p>$ sudo apt-get update   $ sudo apt-get install docker-compose-plugin</p> <p>Confirm that docker compose is installed</p> <pre><code>$ docker compose --version\n</code></pre> <p>Note</p> <p>In order for Mole to automatically generate keys/certificates for https, the <code>openssl</code> command must be installed on the host. This is generally the case by default.</p> <p>3) Poetry</p> <p>Requires Python 3.7+ (Windows, MacOS, Linux). See Poetry System/Install Requirememets for further instructions.</p> <pre><code>$ curl -sSL https://install.python-poetry.org | python3 - --version 1.2.0\n</code></pre> <p>Confirm Poetry is installed</p> <pre><code>$ poetry --version\n</code></pre> <p>Setup poetry virtual enviroment. Ensure the command is ran in the same directory as <code>pyproject.toml</code> and <code>poetry.lock</code>.</p> <pre><code>$ poetry install\n</code></pre>"},{"location":"getting_started.html#services","title":"Services","text":"<p>Mole is composed of a number of different services including the following:</p> <ul> <li>proxy     : A Traefik-based reverse proxy to expose services at paths and via https.                   Accessible on host port 8080 (http://localhost:8080)</li> <li>postgres  : A PostgreSQL database server.                   Accessible on host port 5432.</li> <li>pulsar    : An Apache Pulsar server. Pulsar is the native messaging platform for Mole.                   Accessible on host ports 6650.                   The Admin API is available at http://localhost:8090</li> <li>django    : A Django-based REST API server.  It also serves static frontend content.                   Accessible on host port 8000 (e.g., http://localhost:8000) or domain root (e.g., http://localhost)                     - Note: A browseable API is also available at /api/. (e.g., http://localhost/api/)</li> <li>angular    : An Angular development server. As changes are made in the code, the server live-updates the UI.                   Accessible on host port 4200 (e.g., http://localhost:4200) or at the path http://localhost/angular/                     - Note: Only accessible after running <code>./ml ang</code> or <code>-a</code> flag on <code>run</code> script</li> <li>redis     : A Redis server.                     - Note: By default the redis service is not exposed outside of the Docker network. To expose Redis externally, use the <code>--unlock-redis</code> command line option to <code>./ml init</code> or <code>./ml run</code> or set the <code>UNLOCK_REDIS</code> environment variable on the host machine. When exposed, Redis will be accessible on host port 6379.</li> <li>docs      : A Mkdocs-based documentation server.                   Accessible on host port 8001 (e.g., http://localhost:8001) or at the path http://localhost/docs/</li> <li>maptiles  : A TileServerGL-based map tile server.                   Accessible on host port 8081 (e.g., http://localhost:8081) or at the path http://localhost/maps/</li> <li>report    : A Plotly Dash-based data visualization and report server.                   Accessible on host port 8400 (e.g., http://localhost:8400) or at the path http://localhost/report/</li> <li>portainer : A Portainer Docker management and monitoring server.                   Accessible on host port 9000 (e.g., http://localhost:9000) or at the path http://localhost/portainer/ with:                      - user: <code>admin</code>                     - password: <code>password</code></li> </ul>"},{"location":"getting_started.html#https-optional","title":"Https (optional)","text":"<p>All http endpoints can be made available via https. Certificates/keys are automatically generated the first time <code>./ml init</code> is run. See below to generate new keys.</p>"},{"location":"getting_started.html#adding-the-mole-certificate-authority-certificate-to-chrome","title":"Adding the Mole Certificate Authority certificate to Chrome","text":"<p>Warning</p> <p>Please ensure you understand the security implications before importing the Mole Certificate Authority into your browser.</p> <p>In order to \"trust\" the Mole certificate, perform the following:</p> <ul> <li>Open Chrome <code>Settings</code></li> <li>Select <code>Security</code></li> <li>Select <code>Manage Certificates</code></li> <li>Select <code>Authorities</code></li> <li>Click <code>Import</code></li> <li>Browse to the location of the Mole repository under <code>mole/traefik/certificates</code></li> <li>Select <code>moleCA.pem</code></li> <li>Click <code>Trust this certificate for identifying websites</code></li> </ul> <p>If you are trying to \"trust\" the Mole certificate on a machine other than the Mole server, first copy the <code>mole/traefik/certificates/moleCA.pem</code> file from the Mole server to an accssible location, then browse to this location when selecting the certificate to import.</p> <p>Note</p> <p>Once the Mole Certificate Authority certificate has been imported it should be at the top of the list as <code>org-_Mole</code>. If the CA certificate is updated in the server, it must be replaced in the browser as well.</p>"},{"location":"getting_started.html#generating-keys","title":"Generating keys","text":"<p>Although <code>./ml init</code> automatically generates keys/certificates the first time it is run, it may be useful to replace or update them for various reasons. The <code>./ml</code> script includes a helper to generate new keys: <code>./ml keys</code>. </p> <p>This helper has options for selectively generating only the certificate authority (<code>./ml keys --ca</code>) or the server (<code>./ml keys --server</code>) keys. This is useful, for example, to re-generate the server keys while keeping the same certificate authority.</p> <p>In order for the certificate to be valid for hosts or IPs other than <code>localhost</code> or <code>127.0.0.1</code>, the desired hosts/IPs must be added to <code>traefik/configuration/cert.ext</code> under the <code>alt_names</code> section.</p> <p>Once the <code>cert.ext</code> file has been updated with new hosts/IPs, a new server certificate must be generated using <code>./ml key --server</code>. This will generate a new \"server\" certificate using the existing Certificate Authority. I.e., no new Certificate Authority key/cert is generated when the <code>--server</code> flag is used.</p> <p>Note</p> <p>Once the server certificate has been updated with new hosts/IPs, Chrome should automatically trust the new one for those IPs. I.e., there is no need to re-import the Mole Certificate Authority in Chrome unless it was re-generated as well.</p>"},{"location":"getting_started.html#running","title":"Running","text":"<p>The <code>ml</code> script at the root of the Mole repo can be used to build containers, start services, populate dbs, stop services,  or build and serve documentation.  It is structured with a number of subcommands.  Additional help on each command  can be found by passing the <code>--help</code> flag.  E.g., <code>./ml run --help</code>.</p> <p>If this is the first time you are running Mole, use the following command to configure Mole and initialize the database with defaults:</p> <pre><code>$./ml init\n</code></pre> <p>Warning</p> <p>Mole is currently intended to be run within a trusted network. It has not yet been vetted for open-internet deployment. </p> <p>Subsequent runs can use:</p> <pre><code>$./ml run\n</code></pre> <p>See below for additional information on the <code>./ml</code> command and examples of its use.</p> <p>Note</p> <p>If accessing the Mole dashboard produces an HTTP 500 error, the front end (Angular) files may not have been built. These can be built with the following command: <code>$ ./ml ang -b</code></p>"},{"location":"getting_started.html#commands","title":"Commands","text":"<ul> <li><code>init</code>  : Create the Docker containers and initialize a database               based on the available configuration scripts. If no               CONFIGURE_SCRIPT is specified, \"configure_mole\" is               used.              - use <code>-a</code> flag to spin up angular development server             - use <code>-s</code> to skip the static front-end build process             - use <code>--deep-clean</code> to clear containers and volumes before init process</li> <li><code>keys</code>  : Generate CA or server keys/certificates for https.</li> <li><code>run</code>   : Runs a pre-configured container.             - use <code>-q</code> flag to run as a daemon.             - use <code>--lite</code> flag to omit running superflous containters (e.g., portainer, docs, etc.)             - use <code>-a</code> flag to spin up angular development server</li> <li><code>stop</code>  : Stops all containers.</li> <li><code>test</code>  : Runs the Django unit tests. Note: Mole does not run               with this command.  </li> <li><code>shell</code> : Brings up all containers and starts interactive shell.               Note: Mole does not run in this mode.  </li> <li><code>docs</code>  : Build documentation (including OpenAPI schema and graphing database models). Documentation is served at http://localhost:8001 or http://docs.localhost.</li> <li><code>maps</code>  : Serve map tiles at http://localhost:8081 or http://maps.localhost.  Note: Mole does not                run with this command.  See Docs for more information.</li> <li><code>db</code>   : Saves and loads database + media backup archives.             - use <code>-b</code> flag to create a backup archive             - use <code>-l</code> flag to load a backup archive</li> <li><code>management</code> : Load/Save docker images to or from an archive file.                  This archive file can be used to export docker images for use                 on external machines. Also builds containers from images                  in the local repo. </li> <li><code>django</code> : Provides set of tools to interact with Django container. Currently supports                the <code>makemigrations</code> command with <code>-mm</code> flag.</li> <li><code>ang</code>   : Spins up Angular development server.             - use <code>-b</code> flag to build the angular files to be served statically from Django</li> </ul>"},{"location":"getting_started.html#examples","title":"Examples","text":"<p>The following command will build containers and populate the database with initial data using the default \"configure_mole\" script:</p> <pre><code>$./ml init\n</code></pre> <p>Note</p> <p>See below if building the containers hangs.  This may be due to Docker's default DNS server (Google's 8.8.8.8) being blocked on your network.</p> <p>The following command will build containers and populate the database with initial data using a custom \"configure_mole\" script (configure_mole_test):</p> <pre><code>$./ml init configure_mole_test\n</code></pre> <p>The following command will run previously built containers as a daemon:</p> <pre><code>$./ml run -q\n</code></pre> <p>Mole is available at http://localhost.  The browseable API is available at http://localhost/api</p> <p>Tip</p> <p>Documentation is also accessible at http://localhost/docs when Mole is running.</p> <p>The following command will run previously built containers, but not run the map tile server:</p> <pre><code>$./ml run --nomaps\n</code></pre> <p>The following command will stop running containers:</p> <pre><code>$./ml stop\n</code></pre> <p>The following command will spin up the Angular development server:</p> <pre><code>$./ml ang\n</code></pre> <p>The following command will build the Angular files to be served statically from Django:</p> <pre><code>$./ml ang -b\n</code></pre> <p>The following command will build and serve the Mole documentation:</p> <pre><code>$./ml docs\n</code></pre> <p>The following command will run the Mole map tile server alone:</p> <pre><code>$./ml maps\n</code></pre> <p>Note</p> <p>See maps section of documentation for information on creating tiles and configuring the map server.</p> <p>The following command will run the automated tests:</p> <pre><code>$./ml test\n</code></pre> <p>The following command will build Django migration files if schema changes have been made:</p> <pre><code>$./ml django -mm\n</code></pre>"},{"location":"getting_started.html#database-backups","title":"Database Backups","text":"<p>By default, Mole produces database backups before an init and before a database is  loaded, however it has the capability to perform the automatic backups listed below  if the <code>-db</code> flag is used on the <code>init</code> or <code>run</code> commands.</p> <ul> <li>On startup (<code>./ml run -db</code>)</li> <li>On shutdown (<code>^c</code> or <code>./ml stop</code>)</li> <li>Periodically (at the top of every hour)</li> </ul> <p>Regardless of the <code>-db</code> flag being used, backups can be created at anytime using the  command below.</p> <ul> <li>On demand (<code>./ml db -b</code>)</li> </ul> <p>Tip</p> <p>If you would like to not perform a database backup prior to an init, you can use the  <code>-nb</code> flag on the init command: <code>./ml init -nb</code></p> <p>Tip</p> <p>On-demand backups (<code>./ml db -b</code>) can be created with Mole running or stopped; services will be returned to their pre-backup state. </p> <p>In all cases, backups are ultimately launched via a web service. A <code>GET</code> request to http://localhost:8003/backup_db/ or http://backup.localhost/backup_db/ will launch a database backup job. This service is throttled to approximately one request per minute.</p> <p>Tip</p> <p>The database backup web service includes an interactive API documentation served at http://localhost:8003/docs/ or http://localhost/db_backup/docs/</p> <p>There are two optional querystring parameters for the backup service:</p> <ul> <li><code>context</code> represents a string that will be appended to the end of the backup filename to indicate the context for the creation of the backup. (e.g., \"startup\", \"shutdown\", \"on-demand\", etc.). For example a <code>GET</code> request to http://localhost/db_backup/backup_db/?context=docs (via browser, curl, or otherwise) would initiate a database backup with <code>_docs</code> appended to the end of the filename.</li> <li><code>sync</code> indicates that the request shouldn't return a response until the backup has been completed. This is useful if a subsequent action (e.g., clearing the database) needs to ensure the backup has been completed prior to preceeding. Normally the backup call returns immediately and launches the database backup job in the background. Example: http://localhost/db_backup/backup_db/?sync=true.</li> </ul> <p>Note</p> <p>To include both <code>context</code> and <code>sync</code> querystrings, separate them with an ampersand (<code>&amp;</code>) symbol, e.g., http://localhost/db_backup/backup_db/?context=docs&amp;sync=true. If this is done from a terminal <code>curl</code> command, ensure to wrap the url in quotation marks so the <code>&amp;</code> isn't interpreted as a request to background the job. Example: <code>curl \"http://localhost/db_backup/backup_db/?context=docs&amp;sync=true\"</code></p>"},{"location":"getting_started.html#database-backup-location","title":"Database Backup Location","text":"<p>Saved database archives are stored in the <code>db_backup/backups/</code> directory.  The naming convention is <code>mole_backup_&lt;year&gt;-&lt;month&gt;-&lt;day&gt;_&lt;hour&gt;_&lt;minute&gt;-&lt;second&gt;_&lt;stage&gt;.sql</code> where <code>&lt;stage&gt;</code> is a string that indicates the reason the database file was created (e.g., \"start_up\", \"shutdown\", \"pre-init\", \"pre-load\", \"on_demand\", \"periodic\")</p>"},{"location":"getting_started.html#restoring-from-a-database-backup-archive","title":"Restoring from a Database Backup Archive","text":"<p>Database files can be restored using the following command: <code>./ml db -l &lt;archive-name&gt;</code> where the location of <code>&lt;archive-name&gt;</code> is assumed to be in <code>db_backup/backups/</code>. Mole supports loading standalone sql backups, as well as the default  archive format. Mole is also able to import backups from outside of the <code>db_backups/backups</code>  directory if the absolute filepath is provided.</p>"},{"location":"getting_started.html#exporting-docker-images-to-an-external-host","title":"Exporting Docker Images to an External Host","text":"<p>To run the Docker containers you must have Docker images in a local repo. Normally, these containers are built and configured when we execute the <code>init</code> command. However, when a host is unable to access outside networks, it will be unable to build images on initialization. You can load archived images with the <code>ml manage</code> command, and run preconfigured images. </p> <p>Note</p> <p>This feature is currently unable to export on machines with differing architectures. </p> <p>Process: 1) Save project images that have already been populated and constructed. To save all project Docker images into a single      archive use the following command</p> <pre><code>./ml manage -s\n</code></pre> <p>this will save the project Docker images to archive <code>mole_project.tar.gz</code></p> <p>2) You may now export the archive to another host. Simply save to external media or transfer if you have that option.</p> <p>3) Load the images on the new machine:</p> <pre><code>./ml manage -l mole_project.tar.gz\n</code></pre> <p>4) Build the containers:</p> <pre><code>./ml manage -b\n</code></pre> <p>or</p> <pre><code>./ml run\n</code></pre>"},{"location":"getting_started.html#configuring-docker-to-use-a-different-dns-server","title":"Configuring Docker to Use a Different DNS Server","text":"<p>To configure Docker on Ubuntu to use the DNS server listed, edit <code>/lib/systemd/system/docker.service</code> and replace the line </p> <pre><code>ExecStart=/usr/bin/dockerd -H fd://\n</code></pre> <p>with </p> <pre><code>ExecStart=/usr/bin/dockerd --dns &lt;desired_DNS&gt; -H fd://\n</code></pre> <p>You can find out what your current DNS server is with the following command:</p> <pre><code>nmcli dev show | grep 'IP4.DNS'\n</code></pre> <p>Note</p> <p>This is only necessary if building the container images hangs due to the default DNS server being blocked on your network. </p>"},{"location":"maps.html","title":"Maps","text":"<p>TODO</p> <p>Add section on configuring tileserver-gl with json file to serve multiple tilesets and to serve vector tiles.</p> <p>Mole includes a service that serves map tiles using tileserver-gl. To  serve an set of map tiles in the .mbtiles format, place the file in the <code>maps/maptiles</code> folder.  </p> <p>Note</p> <p>The .mbtiles file must have the <code>name</code> and <code>format</code> metadata tables set.  See the .mbtiles spec  for more information.  The instructions below describe adding the appropriate metadata.</p> <p>The tiles will be served at </p> <pre><code>http://localhost/maps/data/&lt;filename_without_extension&gt;/&lt;z&gt;/&lt;y&gt;/&lt;x&gt;.jpg\n</code></pre> <p>A map preview is served at </p> <pre><code>http://localhost/maps/data/&lt;filename_without_extension&gt;\n</code></pre> <p>The <code>maps</code> service runs by default.  To disable it, use the <code>--nomaps</code> flag to <code>./ml run</code>:</p> <pre><code>./ml run --nomaps\n</code></pre>"},{"location":"maps.html#generating-aerial-imagery-map-tiles","title":"Generating Aerial Imagery Map Tiles","text":"<p>This section describes methods for obtaining aerial imagery and processing it into an .mbtiles file to be served by the  Mole map tile server.</p>"},{"location":"maps.html#acquiring-aerial-imagery","title":"Acquiring Aerial Imagery","text":""},{"location":"maps.html#digital-globe-imagery-preferred-method","title":"Digital Globe Imagery (preferred method)","text":"<p>Government employees can get access to Digital Globe imagery.  This generally provides more recent data than that available via the NGA national map site. If you have access to Digital Globe, log in at  https://evwhs.digitalglobe.com . Here you can select a region of interest to download.</p> <ol> <li>Define an area of interest with the drawing tool.</li> <li>Select Generate a tileset<ol> <li>Enter Name</li> <li>Set \"End Zoom Level\" to 18</li> </ol> </li> <li>Click <code>&lt;Save&gt;</code></li> <li>Files will be available under <code>My Imagery --&gt; Library</code> once they have been prepared (takes a while)</li> <li>Uncompress the archive</li> </ol>"},{"location":"maps.html#national-map-imagery-method-2","title":"National Map Imagery (method 2)","text":"<p>Go to  http://viewer.nationalmap.gov/basic/  to download imagery for region of interest.</p> <ol> <li>Select \"Imagery - 1 foot (HRO)\" at the left<ol> <li>Zoom to desired bounding box</li> <li>Click the black square icon </li> <li>Draw desired bounding box.</li> <li>Click the \"Find Products\" button at the top of the left pane.<ol> <li>You can add additional search options (e.g. \"CL\" for only 3 band color imagery or \"4B\" for 4 band color imagery) </li> </ol> </li> </ol> </li> <li>Add all items to the card by pressing the \"+All\" icon for each page in the search returns<ol> <li>This is tedious. Please update this page if you find a better way.</li> </ol> </li> <li>Click \"View Cart\"</li> <li>Click \"List and Export Cart Items\"<ol> <li>This will spawn a file download that corresponds to a .csv file with download links and information about each of the requested images.</li> </ol> </li> <li>Download the files in the .csv file by either using the download manager (java program) </li> <li>Unzip all downloaded files.<ol> <li>This should result in a set of .jp2 files.</li> </ol> </li> </ol>"},{"location":"maps.html#processing-imagery-into-mbtiles","title":"Processing Imagery into .mbtiles","text":""},{"location":"maps.html#digital-globe-imagery","title":"Digital Globe Imagery","text":"<p>The archive downloaded above already has a tiled structure.  We just need to create an mbtiles file.  The  mbutil utility can do this.</p> <ol> <li>Install mbutil<ol> <li><code>git clone http://github.com/mapbox/mbutil.git</code></li> </ol> </li> <li>Change directory to the base of the Digital Globe tileset<ol> <li>Sub-directories at this level should be numbers (e.g., /12/)</li> </ol> </li> <li> <p>Create <code>metadata.json</code> file:</p> <p><code>echo '{\"name\": \"&lt;desired_tileset_name&gt;\", \"format\": \"jpg\"}' &gt; metadata.json</code></p> </li> <li> <p>Create the .mbtiles file:</p> <p><code>mbutil/mb-util --image_format=jpg ./ &lt;filename&gt;.mbtiles</code></p> </li> </ol>"},{"location":"maps.html#national-map-imagery-method-2_1","title":"National Map Imagery (method 2)","text":"<ol> <li>In the folder containing the downloaded .jp2 files, run the following commands:<ol> <li><code>gdalbuildvrt index.vrt *.jp2</code></li> <li><code>gdalwarp -r near --config GDAL_CACHEMAX 3000 -wm 3000 -co compress=jpeg -co photometric=ycbcr -co tiled=yes -t_srs EPSG:3857 index.vrt &lt;filename&gt;.tif</code><ol> <li>see  http://www.gdal.org/gdalwarp.html for more options, particularly for  the resampling method (-r flag)</li> </ol> </li> <li><code>gdaladdo -r nearest --config COMPRESS_OVERVIEW JPEG --config PHOTOMETRIC_OVERVIEW YCBCR &lt;filename&gt;.tif 2 4 8 16 32 64 128</code><ol> <li>see  http://www.gdal.org/gdaladdo.html for more options, particularly for  the resampling method (-r flag)</li> </ol> </li> </ol> </li> <li>Use gdal2tiles.py to cut the tiles.<ol> <li>Install gdal2tiles.py <ol> <li><code>sudo apt-get install python-gdal</code></li> </ol> </li> <li><code>gdal2tiles.py &lt;filename&gt;.tif</code><ol> <li>This will create a folder called  with appropriate tiles in it <li>Use mbutil to create the mbtiles file<ol> <li>Install mbutil<ol> <li><code>git clone http://github.com/mapbox/mbutil.git</code></li> </ol> </li> <li><code>./mbutil/mb-util --scheme=tms &lt;filename&gt;/ &lt;filename&gt;.mbtiles</code></li> </ol> </li>"},{"location":"metadata_keyvalue.html","title":"Metadata Keys/Values","text":"<p>Specifying metadata keys/values reduce the amount of data cleaning required for analysis and reporting, especially in cases where the user types information in. They provide a kind of template for events by suggesting the provided metadata keys and offering a dropdown list of values to assign to those keys. </p>"},{"location":"metadata_keyvalue.html#metadata-key","title":"Metadata Key","text":"<pre><code>example_metadatakey = factories.MetadataKeyFactory(\n    name=\"Behavior\",\n    description=\"\",\n    event_type_list=[factories.EventTypeFactory(name=\"Interaction\")],\n    metadatavalue_set=[factories.MetadataValueFactory(name=\"Appropriate\")],\n)\n</code></pre> <p>Field Descriptions:</p> <ul> <li><code>name</code>: the unique name of the metadata key</li> <li><code>description</code>: the description of the metadata key</li> <li><code>event_type_list</code>: the list of event types this metadata key should be expected on</li> <li><code>metadatavalue_set</code>: the list of expected metadata values this key could be set to</li> </ul>"},{"location":"metadata_keyvalue.html#metadata-value","title":"Metadata Value","text":"<pre><code>factories.MetadataValueFactory(\n    name=\"Appropriate\", \n    description=\"Executed a behavior or maneuver as designed and expected within given tolerances and boundaries\",\n    metadata_keys=[factories.MetadataKeyFactory(name=\"Behavior\"),],\n)\n</code></pre> <p>Field Descriptions:</p> <ul> <li><code>name</code>: the unique name of the metadata value</li> <li><code>description</code>: the description or long form text of the metadata value</li> <li><code>metadata_keys</code>: the list of metadata keys that this value could applied to</li> </ul> <p><code>metadatavalue_set</code> on MetadataKey and <code>metadata_keys</code> on MetadataValue do the same thing. Only one of these fields needs to be populated to tie the key and value together. There is no need to define them both. </p>"},{"location":"point_styles.html","title":"Point Styles","text":""},{"location":"point_styles.html#map-timeline-marker-styles","title":"Map / Timeline Marker Styles","text":"<p>This section describes marker style definition and associating these styles with event_types and entity_types.  These marker styles are used to represent event types and entity types on the map and in the event timeline.  The icons are typically taken from the FontAwesome set or from locally-served .svg icons.</p>"},{"location":"point_styles.html#marker-styles","title":"Marker Styles","text":"<p>Markers are styled using the PointStyle model in Mole.  It has the following fields:</p> <ul> <li>name: Name of this point style</li> <li>description: Description of this point style</li> <li>icon: String representing the icon to be used from the FontAwesome 5 library. Find icons here.</li> <li>color: CSS color code to be applied to the icon (e.g., <code>#FFFFFF</code> for white)</li> <li>use_marker_pin: Boolean field indicating wheather this icon should be shown in a marker pin on the map.  Note this has no effect on the event timeline.</li> <li>marker_color: CSS color code to be applied to the map marker pin icon (e.g., <code>#FFFFFF</code> for white)</li> <li>scale_factor: An optional parameter to adjust sizing of the icon.</li> </ul>"},{"location":"point_styles.html#marker-compositing","title":"Marker Compositing","text":"<p>Point style is an element (foreign key) of the EventType and EntityType models.  In order to determine how a particular event marker is to be styled, the following method is used:</p> <ul> <li>The point style associated with the event's event_type is used as a starting point.</li> <li>The metadata_style_fields (on event_type) is used to override this style.  It represents a list of fields (keys) within the event's metadata whose values represent the name of an entity.  </li> <li>For each entity in this list, the entity's entity_type point_style replaces (for any non-null values) the associated event's event_type point_style in order.  </li> <li>In this way, fields occuring at the end of the metadata_style_fields have precedence over earlier occuring fields.  </li> <li>Note: if only a single point_style element is desired to be replaced by the entity_type style (e.g. the icon string), all other fields within its point_style may be null.</li> <li>The resulting point_style is returned in the event's point_style field.</li> </ul>"},{"location":"pulsar.html","title":"Apache Pulsar","text":""},{"location":"pulsar.html#overview","title":"Overview","text":"<p>Apache Pulsar is a distributed messaging framework. This is the main messaging system used for Mole. Pulsar also has support for stream processing through their service (Pulsar Functions), which we have the ability of leveraging for our use cases.</p> <p>Architecture overview</p> <p>We will be running the standalone mode which contains all the pieces of a Pulsar instance in a single Docker image.</p>"},{"location":"pulsar.html#configuration","title":"Configuration","text":"<p>Configuring Pulsar Functions: Pulsar doesn't start with any Pulsar functions running. In order to run them, they need to be created in the Pulsar broker. There are three ways to deploy these functions. </p> <ul> <li>A Java client interface</li> <li>the <code>pulsar-admin</code> CLI tool</li> <li>HTTP calls to the admin REST API</li> </ul> <p>Of these, we will mainly be using HTTP calls and the <code>pulsar-admin</code> tool. There is a python script that will automatically post any available Pulsar functions it finds on the creation of a new Pulsar Docker container. This script, <code>pulsar/create_functions.py</code>, searches the <code>functions</code> directory for python files, assuming any python files in them to be valid Pulsar functions files and skipping over files prepended an <code>_</code>, and crafts a HTTP payload from a python dict within each Pulsar function file and posts it to the admin REST API. </p> <p>We will only be using the Pulsar Function SDK for Python to develop these functions. This SDK provides a bigger range of functionality that is not available if we were to use the language-native interface. Each Pulsar function file needs at minimum the following:</p> <ul> <li>a dict defining the configuration of the Pulsar function</li> <li>a class that inherits from pulsar.Function that defines a process method with necessary parameters</li> </ul>"},{"location":"pulsar.html#fields","title":"Fields:","text":"<p>The configuration of the Pulsar function has a number of required fields:</p>"},{"location":"pulsar.html#py","title":"py","text":"<p>The location of the python file. Note that this is the path within the docker container. Since the files will be located at <code>/pulsar/functions/</code>, it will need to be of the form <code>/pulsar/functions/&lt;file&gt;</code>.</p> <pre><code>\"py\": \"/pulsar/functions/example_function.py\"\n</code></pre>"},{"location":"pulsar.html#classname","title":"className","text":"<p>The name of the class for the pulsar function. For python, the filename is necessary but not included in the class name. The class name will be used as the default name of the function and corresponding fully qualified function name if one is not specified. The classname in this example would be <code>Example</code>.</p> <pre><code>\"className\": \"example_function.Example\"\n</code></pre>"},{"location":"pulsar.html#inputs","title":"inputs","text":"<p>This is a list of input topics for this function to monitor. The list can span multiple tenants, namespaces, and topics. However, if a regex pattern is used, all topics matching the pattern must  be in the same tenant and namespace. </p> <pre><code>\"inputs\": [\"persistent://public/default/input1\"]\n</code></pre> <p>There are also a number of optional fields that can be specified if necessary.</p>"},{"location":"pulsar.html#output","title":"output","text":"<p>The output topic that any return values will be sent to. If this isn't set manually, the output topic has a default value of <code>{input topic}-{function name}-output</code></p> <pre><code>\"output\": \"persistent://public/default/output\"\n</code></pre>"},{"location":"pulsar.html#logtopic","title":"logTopic","text":"<p>This is the topic where logs for this Pulsar function are sent.</p> <pre><code>\"logTopic\": \"persistent://public/default/log_topic\"\n</code></pre>"},{"location":"pulsar.html#fqfn","title":"fqfn","text":"<p>This is the fully qualified function name (tenant/namespace/function_name). If not explicitly set, it will be inferred from the input topics and class name.</p> <pre><code>\"fqfn\": \"public/default/example_function\"\n</code></pre>"},{"location":"pulsar.html#example-configuration","title":"Example configuration","text":"<pre><code>    body = {\n        \"fqfn\": \"public/default/example_function\",\n        \"py\": \"/pulsar/functions/example_function.py\",\n        \"className\": \"example_function.Example\",\n        \"inputs\": [\"persistent://public/default/input1\"],\n        \"output\": \"persistent://public/default/output\",\n        \"logTopic\": \"persistent://public/default/log_topic\",\n    }\n</code></pre>"},{"location":"pulsar.html#developing-pulsar-functions","title":"Developing Pulsar Functions:","text":"<p>Each Pulsar function needs to inherit from <code>pulsar.Function</code>. This gives us access to a context object that lets us have more functionality. Each function will need a <code>process</code> method.</p> <pre><code>Function.process(self, input, context)\n</code></pre> <p><code>input</code> will be the message in bytes. <code>context</code> will provide a number of useful functions. (https://pulsar.apache.org/docs/en/functions-develop/#context)</p> <p>This <code>process</code> method will be called for each message that comes in on the list of input topics. Any return values from this method will be sent to the output topic. Logs can be sent by using the <code>get_logger</code> method to get a logger object and calling the corresponding method (<code>info</code>, <code>debug</code>, <code>warn</code>, <code>error</code>, <code>critical</code>) on it. The messages created by these log methods are sent to the log topic, where any consumers to that topic can display it.</p> <p>Note</p> <p>The state storage functions (<code>put_state</code>, <code>get_state</code>, <code>incr_counter</code>, <code>get_counter</code>, <code>del_counter</code>) aren't available because the state service is disabled. Use Redis instead.</p> <p>Note</p> <p>If using regex input topics for Pulsar functions, it is possible for the initial messages to not be captured. When a new topic that matches the regex is created by a producer, the Pulsar function has to then create a subscription to that topic which may take up to a minute. In that timespan, any messages on that topic will be missed and not processed by the Pulsar function. Link to Pulsar issue</p>"},{"location":"pulsar.html#testing-pulsar-functions","title":"Testing Pulsar Functions:","text":"<p>Unit testing the Pulsar functions can be done by running a custom docker-compose file.</p> <pre><code>docker compose -f docker-compose-tests.yml up\n</code></pre> <p>This will run any tests in the <code>pulsar/tests</code> directory.</p>"},{"location":"pulsar.html#websockets","title":"Websockets","text":"<p>Pulsar provides a websocket server for clients that do not have a Pulsar library. Clients can connect to this websocket server to receive and send messages on Pulsar topics. Note that the idle timeout for the websocket is 5 minutes. If expected to be idle for more than 5 minutes, the client should expect to reconnect when the websocket closes or send periodic messages to keep the websocket open.</p>"},{"location":"report_generator.html","title":"Report Generator","text":"<p>The Report Generator is web application that utilizes the Plotly Dash Python Library  to generate, print, and export meaningful data visualizations. </p> <p>The Report Generator is ideal for:</p> <ul> <li> <p>Generating data visualization to further analyze collected data with Mole.</p> </li> <li> <p>Generating data visualization and analyze output as a standalone Dash app via API endpoint or CSV upload.</p> </li> </ul>"},{"location":"report_generator.html#about-the-app","title":"About the App","text":"<p>This is an interactive, multi-page report that dynamically creates figures with an API endpoint data and/or CSV data. The report also incorporates custom styling to provide distinct pages for PDF printing and the ability to  export figures to static image file formats like PNG, SVG, or PDF.</p>"},{"location":"report_generator.html#getting-started","title":"Getting Started","text":"<p>Navigate to the root directory of the project and run the following command:</p> <p><code>$ ./ml init</code></p> <p>The Report Generator is available at http://localhost:8400 or  http://localhost/report.</p> <p>Tip</p> <p>If Mole is running on separate machine, you can run the report as a standalone app using <code>./ml report</code>. The report generator has an input box for users to enter an API endpoint manually.</p>"},{"location":"report_generator.html#quickstart","title":"Quickstart","text":"<p>Quickly get started on creating Plotly figures with the report generator.</p>"},{"location":"report_generator.html#create-a-graph-function","title":"Create a graph function","text":"<p>Navigate to <code>/data/graph_functions.py</code> and create a function with the following parameters:</p> <p>For figures using endpoint data, the function name must start with or contain api_. <pre><code>def api_&lt;name_of_your_figure&gt;(endpoint, trial, font_color, plot_color, height, width):\n    # Perform endpoint request and create plotly figure.\n\n    title = \"Name of Your Figure\"\n    if endpoint:\n        data = qf.api_request(f\"{endpoint}/event_data?trial={trial}\")\n    else:\n        # If an endpoint is not provided on the UI, a default endpoint \n        # (Mole event data endpoint) will be used.\n        data = qf.api_request(f\"{event_endpoint}?trial={trial}\")\n\n    # Create a figure with the endpoint data.\n\n    # Figure placeholder\n    fig = empty_figure(font_color, plot_color, height, width, title)\n\n    return fig, \"name_of_your_figure\"\n</code></pre></p> <p>For figures using csv data, the function name must start with or contain csv_. <pre><code>def csv_&lt;name_of_your_figure&gt;(data, filename, font_color, plot_color, height, width):\n    # Create plotly figure. The uploaded data is accessible through parameter 'data'.\n\n    fig = go.Figure()\n    # Create a figure with the csv data.\n\n    return fig, \"name_of_your_figure\"\n</code></pre></p>"},{"location":"report_generator.html#displaying-the-figure","title":"Displaying the figure","text":"<p>By default, the report generator comes with two pages (tabs), api and csv. To display a figure, navigate to <code>/pages</code> and select the respective page. For example, to display a figure on the api page:</p> <pre><code># /pages/api.py\n\ndef metric_layout():\n\"\"\"Return graph figures that uses api data endpoints.\"\"\"\n    return html.Div(\n        [\n            rm.create_figure(id=\"api_&lt;name_of_your_figure\"), \n            rm.create_figure(id=\"api_event_bar\"),\n            rm.create_figure(id=\"api_event_timeline\"),\n        ],\n        className=\"row \",\n        style={\"marginTop\": \"5px\"},\n    )\n</code></pre> <p>Restart the report container and refresh the page to see the newly created figure.</p> <p></p>"},{"location":"report_generator.html#developer-guide","title":"Developer Guide","text":"<p>Inside the <code>report_generator</code> directory, you'll find <code>app.py</code>. This is where the Report Generator (Dash app)  is being executed. </p>"},{"location":"report_generator.html#building-the-report","title":"Building the Report","text":"<p>The <code>/dash</code> directory contains the core components of the report.</p> <ul> <li> <p><code>base.py</code> is the base class of the Dash app. The dynamic callbacks functionality are defined in this file. </p> </li> <li> <p><code>report_modules.py</code> consists of reusable report UI components such as dcc.Graph and dcc.Dropdown, or a custom Div such as <code>html.Div()</code>.</p> </li> <li> <p><code>components.py</code> contains all custom UI callback components.</p> </li> </ul> <p>All data querying, analysis, and visualization are located in <code>/data</code> directory.</p> <ul> <li> <p><code>graph_figures.py</code> contains functions returning <code>plotly</code> figures.</p> </li> <li> <p><code>query_functions.py</code> contains a reusable endpoint request function that covert endpoint data to a DataFrame. All data manipulation and analysis should be done in this file as well.</p> </li> <li> <p><code>utils.py</code> contains other useful data functions such as parsing CSV file.</p> </li> </ul> <p>Each tab on the Report Generator has its own file in the <code>/pages</code> directory. The <code>layout.py</code> contains the functional code to load and display all of the contents for the app.</p>"},{"location":"report_generator.html#creating-figures-via-api-endpoint","title":"Creating Figures via API Endpoint","text":"<p>To retrieve data from an API endpoint, the following function is used:</p> <pre><code># /data/query_functions.py\n\ndef api_request(source):\n\"\"\"Make an API GET-request and return endpoint data as a dataframe.\"\"\"\n    r = requests.get(source)\n\n    if r.status_code == 200:\n        data = r.content \n        endpoint_data = pd.read_csv(io.StringIO(data.decode('utf-8')))\n    else:\n        endpoint_data = pd.DataFrame()\n\n    return endpoint_data\n</code></pre> <p>The parameter <code>source</code> is the endpoint. To get Mole event data, the  <code>source</code> is <code>http://django:8000/api/event_data</code>.</p> <p>Note</p> <p>The default configurations for request is set in <code>config.yml</code>. </p> <p>You can also add filters to the endpoint. For example, to filter event data by  their <code>trial_id</code>:</p> <pre><code>source = \"http://django:8000/api/event_data?trial=1\"\n\nis equivalent to:\n\nsource = f\"{event_endpoint}?trial=1\"\n</code></pre> <p>The <code>event_endpoint</code> is a variable set after reading the <code>config.yml</code>.</p> <p>You can also download the endpoint data by inputting the url in your browser. More examples on Mole endpoints are found in <code>/data/csv/mole_endpoint_examples.csv</code>. The report generator also display these examples by default on a table figure that is found under the CSV Upload tab.</p> <p>To create a figure using the endpoint data, the figure function name in <code>graph_functions.py</code> must start with api_:</p> <pre><code>def api_event_bar(endpoint, trial, font_color, plot_color, height, width):\n\n    fig = Go.Figure()\n\n    return figure, \"name_of_figure\"\n</code></pre> <p>The callback function for this figure will be created dynamically. This dynamically generated callback has the following inputs:</p> <ul> <li> <p>interval-component, fires the callback periodically based on the given polling interval set in <code>layout.py</code></p> </li> <li> <p>url, the current page based on the URL. Switching between Report and Dashboard will trigger the callback.</p> </li> <li> <p>endpoint-session, the string returned by the endpoint input box used for manually entering an API endpoint. This string is assigned to the <code>endpoint</code> paramter.</p> </li> <li> <p>trial-selector, the value returned by the trial selector used for filtering event endpoint data. This value is assigned to the <code>trial</code> parameter.</p> </li> </ul> <p>The output of the callback is <code>figure</code> which is a property of the <code>Graph</code>. Whenever  there's a change in the input, Dash calls the callback function constructs a figure object from <code>graph_functions</code>, and returns it to the app.</p> <p>To display this dynamically generated figure on the report, use <code>report_modules.create_figures()</code> on the desired page layout.  <pre><code># /pages/api.py\n\ndef metric_layout():\n\"\"\"Return graph figures that uses api data endpoints.\"\"\"\n    return html.Div(\n        [\n            rm.create_figure(id=\"api_event_bar\"),\n        ],\n        className=\"row \",\n        style={\"marginTop\": \"5px\"},\n    )\n</code></pre> The id is the name of the figure function. In this example, the id is <code>api_event_bar</code>.</p> <p>Tip</p> <p>The Report Generator comes with two sample figures. You can generate random events to Mole by clicking the <code>GENERATE EVENT</code> button after entering Mole credentials on the report generator dashboard. NOTE: The events generated will be posted to the current trial on Mole, not the selected trial on the report generator.</p>"},{"location":"report_generator.html#creating-figures-via-csv","title":"Creating Figures via CSV","text":"<p>By default, the app will automatically upload the <code>mole_endpoint_examples.csv</code> from <code>/data/csv</code>. This can be changed by modifying the DEFAULT_DATA  in <code>utils.py</code>. There is also an option to upload your own file from the report dashboard.</p> <p>To dynamically create a figure with uploaded data, the figure function name in <code>graph_functions.py</code> must start with csv_: <pre><code>def csv_table(data, filename, font_color, plot_color, height, width):\n\n    fig = go.Figure()\n\n    return fig, \"export_filename\"\n</code></pre></p> <p>The dynamic callback for this CSV-figure has the following inputs:</p> <ul> <li> <p>url, the current page based on the URL. Switching between Print and Dashboard will trigger the callback.</p> </li> <li> <p>csv-session, the data acquired from upload.</p> </li> <li> <p>csv-filename-session, the filename of the uploaded data.</p> </li> </ul> <p>The output of the callback is <code>figure</code> which is a property of the <code>Graph</code>. Whenever  there's a change in the input, Dash calls the callback function constructs a figure object from <code>graph_functions</code>, and returns it to the app.</p>"},{"location":"report_generator.html#exporting-figures","title":"Exporting Figures","text":"<p>To export figures from the Report Generator, simply click the Export button on the  dashboard. Every figure in the dashboard can be exported as long the function  in <code>graph_functions.py</code> has the export decorator from <code>export.py</code>. </p> <p>To use the export decorator, create the decorator:</p> <pre><code>import report_generator.data.export as re\n\nbulk_export = re.make_bulk_exported()\n</code></pre> <p>Then for any functions that create a figure, ensure that it can accept any number of parameters using args and kwargs. All figure functions with the same export call will be passed with the same set of parameters. Ensure all functions in <code>graph_functions.py</code> with export decorator to return a figure and title.</p> <p>By default, there are two decorators in place:</p> <ul> <li> <p>bulk_export, this export decorator is used for exporting figures that uses endpoint data. It will export every figure for every trial.</p> </li> <li> <p>export, this export decorator is used for exporting figures that uses CSV data. </p> </li> </ul> <pre><code># /data/graph_functions.py\n\n@bulk_export\ndef example(trial, font_color, plot_color, height, width):\n\n    fig = go.Figure()\n\n    title = \"Example\"\n    fig.update_layout(\n        title = title\n    )\n\n    return fig, f\"example_{trial}\"\n</code></pre> <p>All exported figures can be found in <code>report/exported_figures</code>.</p>"},{"location":"report_generator.html#pdf-printexport","title":"PDF Print/Export","text":"<p>The Report Generator comes with a dedicated page that is styled specfically for PDF exporting. This page can be found at http://localhost/report/Print. To export the report to a PDF, simply click the <code>export</code> button on the top right corner of the page.</p>"},{"location":"scenario_scripts.html","title":"Description","text":"<p>Scenario Scripts allow you to describe a sequence of events to occur after a certain  event occurs and trial Conditions are met. Scripted Events are scheduled to post after  a defined amount of time from either the initiating event or the Scripted Event that  precedes it.</p>"},{"location":"scenario_scripts.html#configuration","title":"Configuration","text":""},{"location":"scenario_scripts.html#step-1-describe-the-script","title":"Step 1: Describe the Script","text":"<p>A Script describes:</p> <ul> <li><code>initiating_event_types</code>: a list of event types that can initiate the Script</li> <li><code>conditions</code>: optional Conditions that need to be met for the Script to run</li> <li><code>conditions_pass_if_any</code>: When multiple conditions are used, will use OR logic      instead of AND</li> <li><code>run_limit</code>: an optional number of times the Script is allowed to run in a given trial</li> <li><code>auto_repeat_count</code>: an optional number of times to repeat the script when it's triggered</li> <li><code>cancelling_event_type</code>: the event type that can cancel scheduled events</li> <li><code>scripted_event_head</code>: the first Scripted Event in the Script sequence*</li> </ul> <p>Note</p> <p>*Scripts are composed of a linked list of Scripted events, which we refer to as the  Script sequence.</p>"},{"location":"scenario_scripts.html#example","title":"Example:","text":"<pre><code>trial_start_script = auto_factories.ScriptFactory(\n    name=\"On Trial Start Script\",\n    initiating_event_types=[trial_start_event_type],\n    conditions=[has_trial_init_condition], # See Step 3\n    run_limit=5,\n    auto_repeat_count=3,\n    cancelling_event_type=cancel_scheduled_events_event_type,\n    scripted_event_head=... # See Step 2\n)\n</code></pre>"},{"location":"scenario_scripts.html#step-2-describe-the-scheduled-events","title":"Step 2: Describe the scheduled events","text":"<p>Scripted Events describe:</p> <ul> <li><code>event_type</code>: an event type to post</li> <li><code>delay_seconds</code>: the time delay before posting the event</li> <li><code>conditions</code>: Conditions to be met for the event to post</li> <li><code>conditions_pass_if_any</code>: When multiple conditions are used, will use OR logic      instead of AND</li> <li><code>add_event_metadata</code>: metadata to attach to the event being created</li> <li><code>copy_trigger_metadata</code>: copies metadata from triggering event to the event being      created</li> <li><code>next_scripted_event</code>: the next event to schedule</li> </ul> <p>Note</p> <p>Though Scripted events can be written in isolation, the linked*list nature would  require you to write their constructors in reverse, so it's recommended to nest the  scheduled events in the Script.</p>"},{"location":"scenario_scripts.html#example_1","title":"Example:","text":"<pre><code>trial_start_script = auto_factories.ScriptFactory(\n    name=\"On Trial Start Script\",\n    initiating_event_types=[trial_start_event_type],\n    conditions=[has_trial_init_condition], # See Step 3\n    cancelling_event_type=cancel_scheduled_events_event_type,\n\n    scripted_event_head=auto_factories.ScriptedEventFactory( # Nested ScriptedEvent\n        name=\"Create other event after 0 seconds\",\n        conditions=[has_trial_init_w_agent_condition], # See step 3\n        delay_seconds=0,\n        event_type=other_event_type,\n        add_event_metadata={\"note\":\"Created by script.\"},\n        copy_trigger_metadata=True,\n\n        next_scripted_event=auto_factories.ScriptedEventFactory( # Nested ScriptedEvent\n            name=\"Create unassigned event after 15 seconds\",\n            conditions=[ugv_prox_in_condition, has_trial_init_condition], # See step 3\n            conditions_pass_if_any=True,\n            delay_seconds=15,\n            event_type=unassigned_event_type,\n            event_metadata={\"note\":\"Created by script.\"},\n\n            next_scripted_event=None\n        )\n    )\n)\n</code></pre>"},{"location":"scenario_scripts.html#step-3-describe-conditions","title":"Step 3: Describe Conditions","text":"<p>Script Conditions can be applied to both the Script and Scripted events. The Condition  will be checked by Mole, and if met, Mole will either allow the Script to be run or  allow the event to be scheduled. All rules within a condition use an OR operation; if  any rule is true, the Condition will be true. If you would like an AND condition, break  rules out into separate Conditions. The following rules can be set:</p> <ul> <li><code>trial_has_event</code>: evaluates to <code>true</code> if trial contains the specified event type</li> <li><code>trial_missing_event</code>: evaluates to <code>true</code> if trial does not contain the specified      event type</li> <li><code>event_metadata_contains</code>: evaluates to <code>true</code> if event from <code>trial_has_event</code>      contains the specified string</li> <li><code>event_metadata_excludes</code>: evaluates to <code>true</code> if event from <code>trial_has_event</code>      excludes the specified string</li> <li><code>trigger_metadata_contains</code>: evaluates to <code>true</code> if the triggering event's metadata      contains the specified string</li> <li><code>trigger_metadata_excludes</code>: evaluates to <code>true</code> if the triggering event's metadata      excludes the specified string</li> </ul> <p>Note</p> <p>The <code>event_metadata_contains</code> field only applies in  conjunction with <code>trial_has_event</code>, in which the condition will only be met if the  event defined in <code>trial_has_event</code> has metadata that contains the string described  in <code>event_metadata_contains</code>. </p>"},{"location":"scenario_scripts.html#example_2","title":"Example:","text":"<pre><code>has_trial_init_w_agent_condition = auto_factories.ScriptConditionFactory(\n    trial_has_event = trial_init_event_type,\n    trial_missing_event = trial_end_event_type,\n    event_metadata_contains = \"agent\",\n    event_metadata_excludes = \"bad_meta\",\n    trigger_metadata_contains = \"node\",\n    trigger_metadata_excludes = \"bad_meta\",\n)\n</code></pre>"},{"location":"scenario_scripts.html#step-4-add-script-to-scenario","title":"Step 4: Add Script to Scenario","text":"<p>Scripts are associated with Scenarios, but tracked by Trials. This primarily applies to  run limits, where the Script can be limited to a certain number of runs for the given  Trial. Conditions are also applied in the scope of the given Trial.</p>"},{"location":"scenario_scripts.html#example_3","title":"Example:","text":"<pre><code>scripted_scenario = auto_factories.ScenarioFactory(\n    name=\"Example Scripted Scenario\",\n    description=\"Example Scripted Scenario\",\n    location=camp_roberts_location,\n    test_method=interactive_fiducial_method,\n    scripts=[\n        trial_start_script,\n        trial_end_script\n    ]\n)\n</code></pre>"},{"location":"trigger_setup.html","title":"Trigger Setup","text":""},{"location":"trigger_setup.html#event-generator-pulsar-function","title":"Event Generator Pulsar Function","text":"<p>There is a Pulsar function that aims to implement a Python based event generator, contained in <code>functions/_simple_event_gen.py</code>. This function is aided by a Python application (<code>message_cacher.py</code>) that caches relevant incoming Pulsar messages into a Redis cache with timestamped storage and easy retrieval for the purposes of trigger evaluation. This python application will reside in its own separate Docker container. As an overview,  a trigger can be established by creating a Trigger model instance. Evaluation of a trigger involves its condition and the condition variables used. The condition is a string that is evaluated in an Python-like interpreter.</p> <p>Note: The file that contains the Pulsar function is prepended by an underscore to stop the pulsar function auto-discovery in <code>create_functions.py</code> from creating the function. <code>message_cacher.py</code> will create this function once it can retrieve the input topics from the Django server. </p>"},{"location":"trigger_setup.html#trigger-setup","title":"Trigger Setup","text":"<p>To create a <code>Trigger</code>, you need to have some pre-requisites models first, starting with the <code>ConditionVariable</code>. The <code>ConditionVariable</code> is used during the <code>Trigger</code> condition evaluation, where it acts as a placeholder. </p>"},{"location":"trigger_setup.html#conditionvariable","title":"ConditionVariable","text":"Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nmy_condition_var = dcm.ConditionVariable.objects.create(\n    name=\"node_state_var\",\n    description=\"node state (e.g. unconfigured / active)\",\n    variable=\"node_state_var : /node/status.state\",\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nmy_condition_var = factories.ConditionVariableFactory(\n    name=\"node_state_var\",\n    description=\"node state (e.g. unconfigured / active)\",\n    variable=\"node_state_var : /node/status.state\",\n)\n</code></pre> <p>The <code>variable</code> field should be in a similar format to the example: <code>condition_variable_name : /topic/name.field_name</code>. </p> <p><code>condition_variable_name</code> is the variable name used in the <code>Trigger</code> evaluation. </p> <p>The topic name will be converted to underscores (i.e. <code>/topic/name</code> -&gt; <code>_topic_name</code>) and used as part of a Pulsar topic name. The Pulsar tenant and namespace cannot be changed and are set to <code>public</code> and <code>default</code> respectively. The resulting full Pulsar topic in this example would be <code>persistent://public/default/_node_status</code>.</p> <p><code>field_name</code> signifies which key to use when replacing the <code>condition_variable_name</code>.</p> <p>When a message is received, the message is expected to have key-value pairs, one of which should have a key indicated by the <code>field_name</code> part of the <code>variable</code> field. <code>condition_variable_name</code> is replaced with the value of that key-value pair and the condition on the <code>Trigger</code> is evaluated. </p> <p>The example in this case will use the value from a message on Pulsar topic <code>persistent://public/default/_node_status</code> with a key of <code>state</code> and replace it wherever <code>node_state_var</code> appears in the <code>Trigger</code>'s condition.</p>"},{"location":"trigger_setup.html#requesteddata","title":"RequestedData","text":"<p><code>RequestedData</code> is any other data that you wish to post to some API endpoint. </p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\nmy_requested_data = dcm.RequestedData.objects.create(\n    name=\"Node Subject\",\n    description=\"Get subject entity when node registers\",\n    destination_url=\"$EVENT$\",\n    payload={\n        \"subject_entity\": \"/node/status.entity_name\",\n        \"pose_source\": \"[http://localhost:8000/api/pose_sources/1/]\",\n        \"cached_timestamp\": \"$TIME$\",\n    },\n    },\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nmy_requested_data = factories.RequestedDataFactory(\n    name=\"Node Subject\",\n    description=\"Get subject entity when node registers\",\n    destination_url=\"$EVENT$\",\n    payload={\n        \"subject_entity\": \"/node/status.entity_name\",\n        \"pose_source\": \"[http://localhost:8000/api/pose_sources/1/]\",\n        \"cached_timestamp\": \"$TIME$\",\n    },\n)\n</code></pre> <p><code>destination_url</code> indicates where the data will be posted to. <code>$EVENT$</code> is a special string that indicates that the newly created event should be the destination. Since the event url won't be known prior to creating it, the string acts as a workaround to attach relevant data to the event. Another possible destination is the poses API endpoint which will create a pose.</p> <p><code>payload</code> is a Python dictionary where the values are taken from message fields, similar to the <code>ConditionVariable</code>'s <code>variable</code> field. If the value is enclosed in square brackets, that static data will be posted. If the value is $EVENT$ or $TIME$, it will be replaced with the associated event or a timezone-aware datetime of the current time respectively. In this example, the <code>subject_entity</code>'s value is the <code>entity_name</code> field on a message from the Pulsar topic <code>persistent://public/default/_node_status</code>. The value of <code>pose_source</code> would be the literal string <code>\"http://localhost:8000/api/pose_sources/1/\"</code> regardless of the message contents. The value of <code>cached_timestamp</code> would be the time that the message is cached into Redis by <code>message_cacher.py</code>.</p>"},{"location":"trigger_setup.html#trigger","title":"Trigger","text":"<p>With these pieces in place, you can create a <code>Trigger</code> now.</p> Django ORMFactory Boy <pre><code>import data_collection.models as dcm\ndcm.Trigger.objects.create(\n    name=\"Node Online Trigger\",\n    key=\"node_online\",\n    description=\"Create event when a node comes online.\",\n    is_active=True,\n    creates_event=True,\n    condition='node_state_var == \"online\"',\n    condition_variables=[my_condition_var],\n    requested_dataset=[my_requested_data],\n    event_type=node_online_event_type,\n)\n</code></pre> <pre><code>from data_collection.factories import factories\nfactories.TriggerFactory(\n    name=\"Node Online Trigger\",\n    key=\"node_online\",\n    description=\"Create event when a node comes online.\",\n    is_active=True,\n    creates_event=True,\n    condition='node_state_var == \"online\"',\n    condition_variables=[my_condition_var],\n    requested_dataset=[my_requested_data],\n    event_type=node_online_event_type,\n)\n</code></pre> <p><code>key</code> is a unique string that identifies the <code>Trigger</code>. </p> <p><code>is_active</code> is a flag that will tell the event generator whether or not to monitor the <code>Trigger</code> condition. The flag is currently only read on start-up. It won't update while the event generator is running.</p> <p><code>creates_event</code> is a flag that indicates whether or not the <code>Trigger</code> evaluation creates an event.</p> <p><code>condition</code> is a string that represents the Python-like expression that is evaluated as the condition for the <code>Trigger</code>.</p> <p><code>condition_variables</code> is a list of <code>ConditionVariables</code> that is used in the <code>condition</code>. It is an error if the <code>condition</code> contains any variables that doesn't have a corresponding <code>condition_variable</code>.</p> <p><code>requested_dataset</code> is a list of <code>RequestedData</code> that will be attached to their respective destinations if this <code>Trigger</code> evaluates True.</p> <p><code>event_type</code> is the default event type for events created by the <code>Trigger</code>. The event type can be overridden if it is present in the message for the <code>Trigger</code>. This is not used if  <code>creates_event</code> is False.</p>"},{"location":"usage.html","title":"API Usage","text":"<p>For the API during an active test mission, we'll generally be concerned with creating one of the following: <code>Poses</code>, <code>Events</code>, <code>Notes</code>, <code>Images</code>. As opposed to the configuration which was largely done through the Django custom command, these will be created through their respective API endpoints.</p>"},{"location":"usage.html#poses","title":"Poses","text":"<p>Poses can be used to track entities during each test run. </p> <p>Here is an example of posting a pose.</p> MinimalComprehensive <pre><code>import datetime\nimport requests\n\npose_data = {\n    \"lat\": 32.67,\n    \"lon\":  -117.24,\n    \"entity\": \"/api/entities/alpha_1/\",\n    \"pose_source\": \"/api/pose_sources/1/\",\n    \"timestamp\": datetime.datetime.now().isoformat(),\n    \"trial\": 1,\n}\n\nrequests.post(\"http://localhost/api/poses/\", json=pose_data, auth=(\"admin\", \"admin\"))\n</code></pre> <pre><code>import datetime\nimport requests\n\npose_data = {\n    \"lat\": 32.67,\n    \"lon\":  -117.24,\n    \"entity\": \"/api/entities/alpha_1/\",\n    \"pose_source\": \"/api/pose_sources/1/\",\n    \"timestamp\": datetime.datetime.now().isoformat(),\n    \"trial\": 1,\n    \"elevation\": 0.0,\n    \"heading\": 23.0,\n    \"speed\": 23,\n    \"velocity\": [133.0, 2.0],\n}\n\nrequests.post(\"http://localhost/api/poses/\", json=pose_data, auth=(\"admin\", \"admin\"))\n</code></pre> <p><code>entity</code> is the entity that this pose is for.</p> <p><code>pose_source</code> indicates what type of pose it is. This string should contain the id of a pose source.</p> <p><code>timestamp</code> represents the datetime at which this pose happened. </p> <p><code>trial</code> indicates which specific test run you want to associate this pose with. The same entity can have different paths through the test environment so this isolates the poses to their respective trial. This field would be assigned the trial id.</p> <p><code>elevation</code> is an optional arbitrary float value. This could be used to represent meters from sea level or levels in a building.</p> <p><code>heading</code> is an optional arbitrary float value. A good rule of thumb is to use <code>0.0</code> and/or <code>360.0</code> as north and go clockwise (i.e. east would be <code>90.0</code>)</p> <p><code>speed</code> and <code>velocity</code> are both optional fields. <code>velocity</code> is an array, allowing to provide either 2D or 3D vectors. <code>speed</code> isn't automatically calculated so you'll have to manually set the scalar value. There is no validation that the <code>speed</code> field is the correct speed for the <code>velocity</code> field.</p>"},{"location":"usage.html#events","title":"Events","text":"<p><code>Events</code> will be the primary mode of recording data. These will use the <code>EventTypes</code> created during the configuration and can include any other specific data and/or metadata that you wish to attach.</p> <p>The following is an example of posting an event.</p> MinimalComprehensive <pre><code>import datetime\nimport requests\n\njson_to_post = {\n    \"start_datetime\": datetime.datetime.now().isoformat(),\n    \"event_type\": \"/api/event_types/1/\",\n    \"trial\": \"/api/trials/1/\",\n}\nrequests.post(\"http://&lt;Mole_IP&gt;/api/events/\", json=json_to_post, auth=(\"admin\", \"admin\"))\n</code></pre> <pre><code>import datetime\nimport requests\n\npose_data = {\n    \"lat\": 32.67,\n    \"lon\":  -117.24,\n    \"entity\": \"/api/entities/alpha_1/\",\n    \"pose_source\": \"/api/pose_sources/1/\",\n    \"timestamp\": datetime.datetime.now().isoformat(),\n    \"trial\": 1,\n}\n\npose_post = requests.post(\"http://localhost/api/poses/\", json=pose_data, auth=(\"admin\", \"admin\"))\npose_url = pose_post.headers['Location']\n\njson_to_post = {\n    \"start_datetime\": datetime.datetime.now().isoformat(),\n    \"end_datetime\": \"2022-01-01T08:00:00+00:00\",\n    \"event_type\": \"/api/event_types/1/\",\n    \"trial\": \"/api/trials/1/\",\n    \"start_pose\": pose_url,\n    \"metadata\": {\n        \"entity\": \"usv1\",\n        \"extra_info\": 25.2,\n        \"list_of_important_things\": [\n            \"item1\",\n            \"item2\",\n        ],\n    }\n}\nrequests.post(\"http://&lt;Mole_IP&gt;/api/events/\", json=json_to_post, auth=(\"admin\", \"admin\"))\n</code></pre> <p><code>start_datetime</code> and <code>end_datetime</code> should be a string in the format of ISO 8601. <code>start_datetime</code> is a required field. <code>end_datetime</code> is optional and intended for events with a duration of some kind. It can be omitted and added later or omitted entirely. </p> <p><code>event_type</code> should be a string with the corresponding id for the event type you want to create. </p> <p><code>trial</code> should be a string with the corresponding id for the trial you want to attach this event to.</p> <p><code>start_pose</code> is an optional field that ties a pose to this event. Its value should be the url of a previously created pose. Currently, it is not possible to create both a pose and event in the same HTTP request. You can use this start pose field to indicate something like an interaction happening at a specific location. </p> <p><code>metadata</code> should be a Python dictionary of relevent data and metadata about the event. If not supplied, it will default to an empty dictionary. </p> <p>The target url should be whatever IP the Mole server is hosted on. This could be an IP or <code>http://localhost</code> if posting locally from the same host. </p> <p>Note</p> <p>The crendentials used are based off the example configuration in the basic configuration. If these have changed, make sure to use the correct username and password.</p>"},{"location":"usage.html#notes","title":"Notes","text":"<p>Notes provide an area to supplement events with free-form notes. All notes must be attached to an event.  <pre><code>import datetime\nimport requests\n\njson_to_post = {\n    \"tester\": \"/api/testers/1/\",\n    \"note\": \"Test note here\",\n    \"event\": \"/api/events/1/\",\n}\n\nrequests.post(\"http://localhost/api/notes/\", json=json_to_post, auth=(\"admin\", \"admin\"))\n</code></pre></p>"},{"location":"usage.html#images","title":"Images","text":"<p>Images can be useful for traceability and debugging. You can attach an image(s) to any event. <pre><code>import datetime\nimport requests\n\nfiles = {\n    \"image\": open('/directory/to/image.png', 'rb'),\n}\ndata = {\n    \"image_type\": \"/api/image_types/1/\",\n    \"event\": \"/api/events/1/\",\n    \"timestamp\": datetime.datetime.now().isoformat(),\n}\n\nr = requests.post(\"http://localhost/api/images/\", files=files, data=data, auth=(\"admin\", \"admin\"))\n</code></pre></p>"},{"location":"usage.html#bulk-posts","title":"Bulk POSTs","text":"<p>Mole also has the ability to create multiple instances for a single HTTP POST request. Currently this ability only exists for events and poses. To use this ability, simply pass a list of objects rather than a single object. This feature is useful if single posts are too slow for the level of throughput desired and increasing the number of Gunicorn/Django workers is not possible. Testing might be required to determine the optimal number of objects to post during each request. Also note that Pulsar messages will not be sent for any bulk events or poses. Any Pulsar functions that are tracking the event log will not run for these events. </p> Single instanceMultiple instances <pre><code>POST /api/events\n{\n    \"start_datetime\": &lt;ISO_datetime&gt;,\n    \"start_pose\": &lt;pose_url&gt;,\n    \"event_type\": &lt;event_type_url&gt;,\n    \"metadata\": &lt;metadata&gt;,\n}\n</code></pre> <pre><code>POST /api/events\n[\n    {\n        \"start_datetime\": &lt;ISO_datetime&gt;,\n        \"start_pose\": &lt;pose_url&gt;,\n        \"event_type\": &lt;event_type_url&gt;,\n        \"metadata\": &lt;metadata&gt;,\n    },\n    {\n        \"start_datetime\": &lt;ISO_datetime&gt;,\n        \"start_pose\": &lt;pose_url&gt;,\n        \"event_type\": &lt;event_type_url&gt;,\n        \"metadata\": &lt;metadata&gt;,\n    },\n    {\n        \"start_datetime\": &lt;ISO_datetime&gt;,\n        \"start_pose\": &lt;pose_url&gt;,\n        \"event_type\": &lt;event_type_url&gt;,\n        \"metadata\": &lt;metadata&gt;,\n    }\n]\n</code></pre>"},{"location":"utilities_event_mocker.html","title":"Event Mocker","text":"<p>The Event Mocker is a tool used to create and post random and/or sequenced events to  Mole. There are two different ways of using the event mocker: Random Event Mocking and Event Sequence Mocking. </p> <p>Random Event Mocking is useful for:</p> <ul> <li>load testing</li> <li>quickly getting events in the database</li> </ul> <p>Event Sequence Mocking is useful for:</p> <ul> <li>testing behavior when certain events happen in sequence</li> <li>simulating a realistic trial</li> </ul>"},{"location":"utilities_event_mocker.html#configuration","title":"Configuration","text":"<p>The first step is to ensure the python requests library is installed on your machine.</p> <pre><code>pip install requests\n</code></pre> <p>The script requires at least one configuration file passed as an argument. Below is an example of a configuration file that meets the requirements for both Random Event  Mocking and Event Sequence Mocking.</p> <pre><code>{\n    \"username\": \"admin\",\n    \"password\": \"admin\",\n    \"trial_duration\": {\n        \"hours\": 1,\n        \"minutes\": 0\n    },\n    \"bounding_box\": {\n        \"min_point\": {\n            \"lat\": 32.657360,\n            \"lon\": -117.283920\n        },\n        \"max_point\": {\n            \"lat\": 32.740647,\n            \"lon\": -117.157868\n        }\n    },\n    \"event_metadata\": {\n        \"detail\": [\"Event created by Mole Utilities Event Generator.\"],\n        \"key_1\": [\"choice_1\", \"choice_2\", \"choice_3\"],\n        \"key_2\": [\n            \"single_choice\",\n            [1, 2, 3],\n            [\"a\", \"b\", \"c\"]\n        ],\n        \"key_n\": [\n            {\"nested_1\": \"1a\"},\n            {\"nested_2\": \"2b\"},\n            {\"nested_3\": \"3c\"}\n        ]\n    },\n    \"event_type_metadata\": {\n        \"Node Online\": {\n            \"node\": [\"node-1\", \"node-2\", \"node-3\"]\n        }\n    },\n    \"event_count\": 100,\n    \"sequence_order\": [\n        [\"Start\", 1],\n        [\"RANDOM\", 50],\n        [\"End\", 1]\n    ],\n    \"sequences\": {\n        \"Start\": [\n            [\"Node Online\", 50],\n            [\"Trial Start\", 1]\n        ],\n        \"End\": [\n            [\"Trial End\", 1],\n            [\"Safety Stop\", 1]\n        ]\n    },\n    \"excluded_types\": [\n        \"Unassigned\",\n        \"Ignore\"\n    ],\n}\n</code></pre> <p>Required Keys:</p> <ul> <li> <p><code>username</code>: string. Admin username. </p> </li> <li> <p><code>password</code>: string. Admin password.</p> </li> <li> <p><code>trial_duration</code>: dict. Window of time for events to occur in.</p> <ul> <li><code>hours</code>: int. Number of hours for the current trial.</li> <li><code>minutes</code>: int. Number of minutes for the current trial.</li> </ul> </li> <li> <p><code>bounding_box</code>: dict. Geographical area for events to be plotted in.</p> <ul> <li><code>min_point</code>: dict. Bottom left corner of area.<ul> <li><code>lat</code>: float. Latitude value for bottom left point.</li> <li><code>lon</code>: float. Longitude value for bottom left point.</li> </ul> </li> <li><code>max_point</code>: dict. Top right corner of area.<ul> <li><code>lat</code>: float. Latitude value for top right point.</li> <li><code>lon</code>: float. Longitude value for top right point.</li> </ul> </li> </ul> </li> <li> <p><code>event_metadata</code>: dict, may be empty. Metadata for every event. Takes a dictionary,          value for each key must be an array. The generator will randomly select one          value from the provided array for each provided key.</p> </li> <li> <p><code>event_type_metadata</code>: dict, may be empty. Metadata for specifc event types. Takes          a dictionary, each key is the name of the event type. The value for each key is          the metadata dictionary. Value for each metadata key must be an array. The          generator will randomly select one value from the provided array for each          provided key.</p> </li> </ul> <p>Keys Relevant for Random Event Mocking:</p> <ul> <li> <p><code>event_count</code>: int. The number of events you would like to generate. </p> <p>Note</p> <p><code>event_count</code> will be overriden if the <code>-c</code> tag is used in the command line  argument.</p> </li> </ul> <p>Keys Relevant for Event Sequence Mocking:</p> <ul> <li> <p><code>sequence_order</code>: array. a list of tuples. The first element of the tuple is the          name of the user-defined sequence. The second element is how many times you          would like to generate that sequence. If you would like to generate random          events within the sequence, use the pre-defined sequence name <code>RANDOM</code> with the          number of random events to generate. Sequences will be generated in order of          array.</p> </li> <li> <p><code>sequences</code>: dict. A dictionary of user-defined sequences. The key is the name of          your sequence. The value is an array of tuples. The value of the first tuple          element is the event type name. The value of the second element is the number of         times that event type should occur. Events will be generated in order of array.</p> </li> </ul> <p>Optional:</p> <ul> <li><code>excluded_types</code>: array, optional. An array of event types to exclude when mocking         random events.</li> </ul>"},{"location":"utilities_event_mocker.html#run","title":"Run","text":"<p>The script requires one configuration file that provides the required keys, or multiple  configuration files that, when composed, provide the required keys. If you include  multiple configuration files, key conflicts will be handled by choosing the value from  the latest file.</p> <p>Random Event Mocking</p> <p>From the <code>/utilities</code> directiory, run:</p> <pre><code>python mock_events.py path/to/your/config.json path/to/another/config.json\n</code></pre> <p>Tip</p> <p>To override the number of random events to mock, add tag <code>-c</code> followed by the number      of events. Example:</p> <pre><code>python mock_events.py -c 100 path/to/your/config.json\n</code></pre> <p>Event Sequence Mocking</p> <p>From the <code>/utilities</code> directiory, run:</p> <pre><code>python mock_events.py -seq path/to/your/config.json path/to/another/config.json\n</code></pre>"},{"location":"utilities_profiler.html","title":"Profiler","text":"<p>Mole includes the Silk profiling tool that can be run with the <code>--profile</code> flag on the <code>./ml init</code> and <code>./ml run</code> commands. When Mole is run with the <code>--profile</code> flag, Silk is available at http://localhost/silk/ or http://localhost:8000/silk/</p> <p>Note</p> <p>It is not recommended to run the Silk profiler in an operational context.</p> <p>From the project's documentation: </p> <p>Silk is a live profiling and inspection tool for the Django framework. Silk intercepts and stores HTTP requests and database queries before presenting them in a user interface for further inspection. It records things like:</p> <ul> <li>Time taken</li> <li>Num. queries</li> <li>Time spent on queries</li> <li>Request/Response headers</li> <li>Request/Response bodies</li> </ul>"},{"location":"utilities_profiler.html#sql-query-inspection","title":"SQL Query Inspection","text":"<p>Silk also intercepts SQL queries that are generated by each request. We can get a summary on things like the tables involved, number of joins and execution time (the table can be sorted by clicking on a column header)</p>"},{"location":"utilities_profiler.html#function-profiling","title":"Function Profiling","text":"<p>Silk can also be used to profile specific blocks of code/functions. It provides a decorator and a context manager for this purpose.</p> <p>Silk has an option to generate binary <code>.prof</code> files for more in depth profiling information.  These files can be viewed in tools like snakeviz or other cProfile tools.  This option is off by default in Mole because it rapidly fills the <code>mole/media/</code> directory with <code>.prof</code> files. It can be enabled by uncommenting the line</p> <pre><code>    # SILKY_PYTHON_PROFILER_BINARY = True\n</code></pre> <p>in <code>mole/mole/settings/settings.py</code>.</p> <p>Tip</p> <p>For more information, see the Silk documentation</p>"}]}